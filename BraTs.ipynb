{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install nnunetv2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uyaqAcois6OK",
        "outputId": "280f8757-af30-4d0b-ce7f-069c43feda76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nnunetv2 in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2.5.1+cu121)\n",
            "Requirement already satisfied: acvl-utils<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.2.2)\n",
            "Requirement already satisfied: dynamic-network-architectures<0.4,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (4.67.1)\n",
            "Requirement already satisfied: dicom2nifti in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (1.13.1)\n",
            "Requirement already satisfied: batchgenerators>=0.25 in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (1.6.0)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.25.0)\n",
            "Requirement already satisfied: SimpleITK>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.20.3)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2024.12.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2.32.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (5.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.13.2)\n",
            "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2024.9.22)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.1.8)\n",
            "Requirement already satisfied: batchgeneratorsv2>=0.2 in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.2.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.8.0)\n",
            "Requirement already satisfied: connected-components-3d in /usr/local/lib/python3.10/dist-packages (from acvl-utils<0.3,>=0.2->nnunetv2) (3.22.0)\n",
            "Requirement already satisfied: blosc2>=3.0.0b4 in /usr/local/lib/python3.10/dist-packages (from acvl-utils<0.3,>=0.2->nnunetv2) (3.0.0b4)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2) (11.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2) (1.0.0)\n",
            "Requirement already satisfied: unittest2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2) (3.5.0)\n",
            "Requirement already satisfied: fft-conv-pytorch in /usr/local/lib/python3.10/dist-packages (from batchgeneratorsv2>=0.2->nnunetv2) (1.2.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (2.36.1)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.2->nnunetv2) (1.3.0)\n",
            "Requirement already satisfied: pydicom>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from dicom2nifti->nnunetv2) (3.0.1)\n",
            "Requirement already satisfied: python-gdcm in /usr/local/lib/python3.10/dist-packages (from dicom2nifti->nnunetv2) (3.0.24.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel->nnunetv2) (6.4.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nnunetv2) (1.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs->nnunetv2) (6.0.2)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.10/dist-packages (from blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2) (1.9.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2) (1.1.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2) (2.10.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2) (9.0.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2) (0.28.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.2->nnunetv2) (3.0.2)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25->nnunetv2)\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: traceback2 in /usr/local/lib/python3.10/dist-packages (from unittest2->batchgenerators>=0.25->nnunetv2) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2) (0.14.0)\n",
            "Requirement already satisfied: linecache2 in /usr/local/lib/python3.10/dist-packages (from traceback2->unittest2->batchgenerators>=0.25->nnunetv2) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->blosc2>=3.0.0b4->acvl-utils<0.3,>=0.2->nnunetv2) (1.2.2)\n",
            "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              },
              "id": "bdfba1760f714fabaf86dee6fd74888d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers"
      ],
      "metadata": {
        "id": "3MpN6mEMFOlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWbpvSmHEMcS",
        "outputId": "cb0e7bc1-1e8f-4247-96ea-a72d8e46662b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['nnUNet_raw'] = '/content/drive/MyDrive/DATASET/nnUNet_raw'\n",
        "os.environ['nnUNet_preprocessed'] = '/content/drive/MyDrive/DATASET/nnUNet_preprocessed'\n",
        "os.environ['nnUNet_results'] = '/content/drive/MyDrive/DATASET/nnUNet_results'"
      ],
      "metadata": {
        "id": "1vqRzUiMFNRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device type: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsMtik-SEMjG",
        "outputId": "86664964-fde7-454a-c80d-7c7103eefde3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device type: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_plan_and_preprocess -d 137 --verify_dataset_integrity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCsuBsWaFrRC",
        "outputId": "0fa81f90-abb4-4249-92ba-13b05d56847c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fingerprint extraction...\n",
            "Dataset137_BraTS2021\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "\n",
            "####################\n",
            "verify_dataset_integrity Done. \n",
            "If you didn't see any error messages then your dataset is most likely OK!\n",
            "####################\n",
            "\n",
            "Experiment planning...\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [138. 174. 136.], 3d_lowres: [138, 174, 136]\n",
            "2D U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 80, 'patch_size': (192, 160), 'median_image_size_in_voxels': array([174., 136.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "3D fullres U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (128, 160, 112), 'median_image_size_in_voxels': array([138., 174., 136.]), 'spacing': array([1., 1., 1.]), 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 1)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
            "\n",
            "Plans were saved to /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/nnUNetPlans.json\n",
            "Preprocessing...\n",
            "Preprocessing dataset Dataset137_BraTS2021\n",
            "Configuration: 2d...\n",
            "100% 15/15 [00:59<00:00,  3.96s/it]\n",
            "Configuration: 3d_fullres...\n",
            "100% 15/15 [00:46<00:00,  3.13s/it]\n",
            "Configuration: 3d_lowres...\n",
            "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset137_BraTS2021. Skipping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install triton"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VHhU50ULhQ_",
        "outputId": "5ceb6f46-64cb-42ac-f6b2-83bf726b9f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 3d_fullres all  -tr nnUNetTrainer_10epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyPLT8rasR9z",
        "outputId": "e64e3a1d-9ceb-4782-bd97-76562fdd029e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 09:50:29.230130: do_dummy_2d_data_aug: False\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-12-25 09:50:37.796474: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 160, 112], 'median_image_size_in_voxels': [138.0, 174.0, 136.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 174, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3477.0, 'mean': 1033.44775390625, 'median': 913.0, 'min': 75.0, 'percentile_00_5': 212.0, 'percentile_99_5': 2637.0, 'std': 484.8674011230469}, '1': {'max': 10061.0, 'mean': 2287.951416015625, 'median': 2029.0, 'min': 14.0, 'percentile_00_5': 686.0, 'percentile_99_5': 6725.0, 'std': 1055.456298828125}, '2': {'max': 2343.0, 'mean': 790.7552490234375, 'median': 771.0, 'min': 13.0, 'percentile_00_5': 89.0, 'percentile_99_5': 1783.0, 'std': 305.4101867675781}, '3': {'max': 4050.0, 'mean': 1813.7210693359375, 'median': 1795.0, 'min': 44.0, 'percentile_00_5': 471.0, 'percentile_99_5': 3388.0, 'std': 624.7869262695312}}} \n",
            "\n",
            "2024-12-25 09:50:40.787181: unpacking dataset...\n",
            "2024-12-25 09:50:56.357296: unpacking done...\n",
            "2024-12-25 09:50:56.383709: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-12-25 09:50:56.412533: \n",
            "2024-12-25 09:50:56.415551: Epoch 0\n",
            "2024-12-25 09:50:56.419441: Current learning rate: 0.01\n",
            "2024-12-25 09:53:36.494379: train_loss -0.4016\n",
            "2024-12-25 09:53:36.505200: val_loss -0.6903\n",
            "2024-12-25 09:53:36.531121: Pseudo dice [0.8646, 0.7755, 0.762]\n",
            "2024-12-25 09:53:36.539351: Epoch time: 160.08 s\n",
            "2024-12-25 09:53:36.545445: Yayy! New best EMA pseudo Dice: 0.8007\n",
            "2024-12-25 09:53:39.125145: \n",
            "2024-12-25 09:53:39.128246: Epoch 1\n",
            "2024-12-25 09:53:39.130649: Current learning rate: 0.0091\n",
            "2024-12-25 09:55:16.851766: train_loss -0.6852\n",
            "2024-12-25 09:55:16.857699: val_loss -0.7256\n",
            "2024-12-25 09:55:16.864910: Pseudo dice [0.906, 0.7742, 0.7701]\n",
            "2024-12-25 09:55:16.871188: Epoch time: 97.73 s\n",
            "2024-12-25 09:55:16.892669: Yayy! New best EMA pseudo Dice: 0.8023\n",
            "2024-12-25 09:55:19.644725: \n",
            "2024-12-25 09:55:19.647733: Epoch 2\n",
            "2024-12-25 09:55:19.649945: Current learning rate: 0.00818\n",
            "2024-12-25 09:57:01.792917: train_loss -0.7389\n",
            "2024-12-25 09:57:01.802483: val_loss -0.775\n",
            "2024-12-25 09:57:01.811066: Pseudo dice [0.9124, 0.8753, 0.7712]\n",
            "2024-12-25 09:57:01.818004: Epoch time: 102.15 s\n",
            "2024-12-25 09:57:01.831590: Yayy! New best EMA pseudo Dice: 0.8074\n",
            "2024-12-25 09:57:04.953259: \n",
            "2024-12-25 09:57:04.956496: Epoch 3\n",
            "2024-12-25 09:57:04.972758: Current learning rate: 0.00725\n",
            "2024-12-25 09:58:47.783472: train_loss -0.7813\n",
            "2024-12-25 09:58:47.796213: val_loss -0.8106\n",
            "2024-12-25 09:58:47.810330: Pseudo dice [0.9221, 0.8629, 0.8113]\n",
            "2024-12-25 09:58:47.817928: Epoch time: 102.83 s\n",
            "2024-12-25 09:58:47.828595: Yayy! New best EMA pseudo Dice: 0.8132\n",
            "2024-12-25 09:58:51.088661: \n",
            "2024-12-25 09:58:51.091915: Epoch 4\n",
            "2024-12-25 09:58:51.094374: Current learning rate: 0.00631\n",
            "2024-12-25 10:00:36.495581: train_loss -0.8022\n",
            "2024-12-25 10:00:36.500641: val_loss -0.812\n",
            "2024-12-25 10:00:36.504245: Pseudo dice [0.951, 0.9254, 0.8264]\n",
            "2024-12-25 10:00:36.507404: Epoch time: 105.41 s\n",
            "2024-12-25 10:00:36.511046: Yayy! New best EMA pseudo Dice: 0.822\n",
            "2024-12-25 10:00:40.383145: \n",
            "2024-12-25 10:00:40.386441: Epoch 5\n",
            "2024-12-25 10:00:40.389858: Current learning rate: 0.00536\n",
            "2024-12-25 10:02:23.379586: train_loss -0.8287\n",
            "2024-12-25 10:02:23.386423: val_loss -0.8327\n",
            "2024-12-25 10:02:23.395143: Pseudo dice [0.9467, 0.9285, 0.8468]\n",
            "2024-12-25 10:02:23.403529: Epoch time: 103.0 s\n",
            "2024-12-25 10:02:23.408385: Yayy! New best EMA pseudo Dice: 0.8305\n",
            "2024-12-25 10:02:26.824641: \n",
            "2024-12-25 10:02:27.219824: Epoch 6\n",
            "2024-12-25 10:02:27.222923: Current learning rate: 0.00438\n",
            "2024-12-25 10:04:10.572521: train_loss -0.8365\n",
            "2024-12-25 10:04:10.582967: val_loss -0.8397\n",
            "2024-12-25 10:04:10.588035: Pseudo dice [0.9511, 0.9285, 0.809]\n",
            "2024-12-25 10:04:10.593439: Epoch time: 103.75 s\n",
            "2024-12-25 10:04:10.602369: Yayy! New best EMA pseudo Dice: 0.8371\n",
            "2024-12-25 10:04:13.645757: \n",
            "2024-12-25 10:04:13.649016: Epoch 7\n",
            "2024-12-25 10:04:13.651433: Current learning rate: 0.00338\n",
            "2024-12-25 10:05:56.202639: train_loss -0.8472\n",
            "2024-12-25 10:05:56.213301: val_loss -0.8694\n",
            "2024-12-25 10:05:56.225649: Pseudo dice [0.9515, 0.9425, 0.8531]\n",
            "2024-12-25 10:05:56.234734: Epoch time: 102.56 s\n",
            "2024-12-25 10:05:56.253270: Yayy! New best EMA pseudo Dice: 0.8449\n",
            "2024-12-25 10:05:59.383952: \n",
            "2024-12-25 10:05:59.387304: Epoch 8\n",
            "2024-12-25 10:05:59.390720: Current learning rate: 0.00235\n",
            "2024-12-25 10:07:42.450942: train_loss -0.8473\n",
            "2024-12-25 10:07:42.456686: val_loss -0.8515\n",
            "2024-12-25 10:07:42.463876: Pseudo dice [0.957, 0.9324, 0.8205]\n",
            "2024-12-25 10:07:42.470170: Epoch time: 103.07 s\n",
            "2024-12-25 10:07:42.475484: Yayy! New best EMA pseudo Dice: 0.8508\n",
            "2024-12-25 10:07:45.818879: \n",
            "2024-12-25 10:07:45.822365: Epoch 9\n",
            "2024-12-25 10:07:45.826175: Current learning rate: 0.00126\n",
            "2024-12-25 10:09:31.623832: train_loss -0.8548\n",
            "2024-12-25 10:09:31.629802: val_loss -0.8605\n",
            "2024-12-25 10:09:31.635829: Pseudo dice [0.9579, 0.9475, 0.8786]\n",
            "2024-12-25 10:09:31.641973: Epoch time: 105.81 s\n",
            "2024-12-25 10:09:31.648726: Yayy! New best EMA pseudo Dice: 0.8585\n",
            "2024-12-25 10:09:35.353425: Training done.\n",
            "2024-12-25 10:09:35.428394: predicting BraTS2021_00000\n",
            "2024-12-25 10:09:35.462605: BraTS2021_00000, shape torch.Size([4, 146, 171, 136]), rank 0\n",
            "2024-12-25 10:10:00.111276: predicting BraTS2021_00002\n",
            "2024-12-25 10:10:00.140131: BraTS2021_00002, shape torch.Size([4, 135, 174, 133]), rank 0\n",
            "2024-12-25 10:10:01.148642: predicting BraTS2021_00003\n",
            "2024-12-25 10:10:01.175587: BraTS2021_00003, shape torch.Size([4, 140, 178, 141]), rank 0\n",
            "2024-12-25 10:10:02.186426: predicting BraTS2021_00005\n",
            "2024-12-25 10:10:02.209338: BraTS2021_00005, shape torch.Size([4, 136, 161, 134]), rank 0\n",
            "2024-12-25 10:10:03.798035: predicting BraTS2021_00006\n",
            "2024-12-25 10:10:03.823005: BraTS2021_00006, shape torch.Size([4, 136, 177, 134]), rank 0\n",
            "2024-12-25 10:10:04.824664: predicting BraTS2021_00008\n",
            "2024-12-25 10:10:04.851410: BraTS2021_00008, shape torch.Size([4, 133, 168, 142]), rank 0\n",
            "2024-12-25 10:10:05.854455: predicting BraTS2021_00009\n",
            "2024-12-25 10:10:05.880016: BraTS2021_00009, shape torch.Size([4, 132, 167, 135]), rank 0\n",
            "2024-12-25 10:10:06.879725: predicting BraTS2021_00011\n",
            "2024-12-25 10:10:06.907415: BraTS2021_00011, shape torch.Size([4, 142, 166, 141]), rank 0\n",
            "2024-12-25 10:10:07.924080: predicting BraTS2021_00012\n",
            "2024-12-25 10:10:07.956114: BraTS2021_00012, shape torch.Size([4, 141, 178, 143]), rank 0\n",
            "2024-12-25 10:10:08.965688: predicting BraTS2021_00014\n",
            "2024-12-25 10:10:09.004196: BraTS2021_00014, shape torch.Size([4, 126, 178, 136]), rank 0\n",
            "2024-12-25 10:10:09.571039: predicting BraTS2021_00016\n",
            "2024-12-25 10:10:09.596138: BraTS2021_00016, shape torch.Size([4, 138, 172, 135]), rank 0\n",
            "2024-12-25 10:10:10.604367: predicting BraTS2021_00017\n",
            "2024-12-25 10:10:10.652586: BraTS2021_00017, shape torch.Size([4, 138, 174, 147]), rank 0\n",
            "2024-12-25 10:10:11.649027: predicting BraTS2021_00018\n",
            "2024-12-25 10:10:11.675602: BraTS2021_00018, shape torch.Size([4, 138, 177, 136]), rank 0\n",
            "2024-12-25 10:10:12.683417: predicting BraTS2021_00019\n",
            "2024-12-25 10:10:12.734169: BraTS2021_00019, shape torch.Size([4, 143, 177, 142]), rank 0\n",
            "2024-12-25 10:10:13.884648: predicting BraTS2021_00020\n",
            "2024-12-25 10:10:13.935109: BraTS2021_00020, shape torch.Size([4, 137, 182, 137]), rank 0\n",
            "2024-12-25 10:10:25.111681: Validation complete\n",
            "2024-12-25 10:10:25.114529: Mean Validation Dice:  0.9028626909881408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 3d_fullres 0  -tr nnUNetTrainer_10epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzzjwX1-TH0d",
        "outputId": "b6ed366a-deb8-4260-e60c-f7000bf930a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 10:12:02.871106: do_dummy_2d_data_aug: False\n",
            "2024-12-25 10:12:02.876010: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 10:12:03.144445: The split file contains 5 splits.\n",
            "2024-12-25 10:12:03.147202: Desired fold for training: 0\n",
            "2024-12-25 10:12:03.164684: This split has 12 training and 3 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-12-25 10:12:25.988582: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 160, 112], 'median_image_size_in_voxels': [138.0, 174.0, 136.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 174, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3477.0, 'mean': 1033.44775390625, 'median': 913.0, 'min': 75.0, 'percentile_00_5': 212.0, 'percentile_99_5': 2637.0, 'std': 484.8674011230469}, '1': {'max': 10061.0, 'mean': 2287.951416015625, 'median': 2029.0, 'min': 14.0, 'percentile_00_5': 686.0, 'percentile_99_5': 6725.0, 'std': 1055.456298828125}, '2': {'max': 2343.0, 'mean': 790.7552490234375, 'median': 771.0, 'min': 13.0, 'percentile_00_5': 89.0, 'percentile_99_5': 1783.0, 'std': 305.4101867675781}, '3': {'max': 4050.0, 'mean': 1813.7210693359375, 'median': 1795.0, 'min': 44.0, 'percentile_00_5': 471.0, 'percentile_99_5': 3388.0, 'std': 624.7869262695312}}} \n",
            "\n",
            "2024-12-25 10:12:28.444195: unpacking dataset...\n",
            "2024-12-25 10:12:42.532646: unpacking done...\n",
            "2024-12-25 10:12:42.560532: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-12-25 10:12:42.577753: \n",
            "2024-12-25 10:12:42.581182: Epoch 0\n",
            "2024-12-25 10:12:42.600801: Current learning rate: 0.01\n",
            "2024-12-25 10:14:43.889856: train_loss -0.3742\n",
            "2024-12-25 10:14:43.895288: val_loss -0.6592\n",
            "2024-12-25 10:14:43.904417: Pseudo dice [0.8509, 0.7702, 0.8334]\n",
            "2024-12-25 10:14:43.909631: Epoch time: 121.32 s\n",
            "2024-12-25 10:14:43.913968: Yayy! New best EMA pseudo Dice: 0.8182\n",
            "2024-12-25 10:14:46.348783: \n",
            "2024-12-25 10:14:46.351564: Epoch 1\n",
            "2024-12-25 10:14:46.353715: Current learning rate: 0.0091\n",
            "2024-12-25 10:16:27.130837: train_loss -0.6795\n",
            "2024-12-25 10:16:27.136894: val_loss -0.6379\n",
            "2024-12-25 10:16:27.143910: Pseudo dice [0.8388, 0.7196, 0.7857]\n",
            "2024-12-25 10:16:27.152089: Epoch time: 100.78 s\n",
            "2024-12-25 10:16:29.274455: \n",
            "2024-12-25 10:16:29.277224: Epoch 2\n",
            "2024-12-25 10:16:29.279511: Current learning rate: 0.00818\n",
            "2024-12-25 10:18:08.756929: train_loss -0.7565\n",
            "2024-12-25 10:18:08.767532: val_loss -0.7178\n",
            "2024-12-25 10:18:08.772882: Pseudo dice [0.8901, 0.8354, 0.813]\n",
            "2024-12-25 10:18:08.779547: Epoch time: 99.48 s\n",
            "2024-12-25 10:18:11.449449: \n",
            "2024-12-25 10:18:11.452847: Epoch 3\n",
            "2024-12-25 10:18:11.455636: Current learning rate: 0.00725\n",
            "2024-12-25 10:19:47.371309: train_loss -0.8062\n",
            "2024-12-25 10:19:47.378493: val_loss -0.6309\n",
            "2024-12-25 10:19:47.384112: Pseudo dice [0.8698, 0.7407, 0.7323]\n",
            "2024-12-25 10:19:47.389068: Epoch time: 95.92 s\n",
            "2024-12-25 10:19:49.431604: \n",
            "2024-12-25 10:19:49.434494: Epoch 4\n",
            "2024-12-25 10:19:49.436605: Current learning rate: 0.00631\n",
            "2024-12-25 10:21:31.881624: train_loss -0.816\n",
            "2024-12-25 10:21:31.892091: val_loss -0.595\n",
            "2024-12-25 10:21:31.900607: Pseudo dice [0.8189, 0.5888, 0.6847]\n",
            "2024-12-25 10:21:31.923911: Epoch time: 102.45 s\n",
            "2024-12-25 10:21:34.201938: \n",
            "2024-12-25 10:21:34.204930: Epoch 5\n",
            "2024-12-25 10:21:34.208093: Current learning rate: 0.00536\n",
            "2024-12-25 10:23:16.695560: train_loss -0.8337\n",
            "2024-12-25 10:23:16.703630: val_loss -0.6696\n",
            "2024-12-25 10:23:16.711118: Pseudo dice [0.879, 0.7541, 0.805]\n",
            "2024-12-25 10:23:16.719275: Epoch time: 102.5 s\n",
            "2024-12-25 10:23:18.935515: \n",
            "2024-12-25 10:23:18.938581: Epoch 6\n",
            "2024-12-25 10:23:18.942254: Current learning rate: 0.00438\n",
            "2024-12-25 10:24:55.335264: train_loss -0.8544\n",
            "2024-12-25 10:24:55.343580: val_loss -0.5984\n",
            "2024-12-25 10:24:55.349664: Pseudo dice [0.8636, 0.6563, 0.7115]\n",
            "2024-12-25 10:24:55.355959: Epoch time: 96.4 s\n",
            "2024-12-25 10:24:57.531451: \n",
            "2024-12-25 10:24:57.534578: Epoch 7\n",
            "2024-12-25 10:24:57.538046: Current learning rate: 0.00338\n",
            "2024-12-25 10:26:37.510884: train_loss -0.858\n",
            "2024-12-25 10:26:37.517500: val_loss -0.6415\n",
            "2024-12-25 10:26:37.525889: Pseudo dice [0.8755, 0.7555, 0.7549]\n",
            "2024-12-25 10:26:37.529956: Epoch time: 99.98 s\n",
            "2024-12-25 10:26:39.738499: \n",
            "2024-12-25 10:26:39.741726: Epoch 8\n",
            "2024-12-25 10:26:39.744460: Current learning rate: 0.00235\n",
            "2024-12-25 10:28:19.043277: train_loss -0.8653\n",
            "2024-12-25 10:28:19.052059: val_loss -0.6303\n",
            "2024-12-25 10:28:19.063527: Pseudo dice [0.8774, 0.6357, 0.7089]\n",
            "2024-12-25 10:28:19.072255: Epoch time: 99.31 s\n",
            "2024-12-25 10:28:21.354254: \n",
            "2024-12-25 10:28:21.375211: Epoch 9\n",
            "2024-12-25 10:28:21.378391: Current learning rate: 0.00126\n",
            "2024-12-25 10:30:06.650373: train_loss -0.8703\n",
            "2024-12-25 10:30:06.662032: val_loss -0.7078\n",
            "2024-12-25 10:30:06.675622: Pseudo dice [0.8926, 0.7626, 0.7841]\n",
            "2024-12-25 10:30:06.685113: Epoch time: 105.3 s\n",
            "2024-12-25 10:30:09.634406: Training done.\n",
            "2024-12-25 10:30:09.741531: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 10:30:09.750261: The split file contains 5 splits.\n",
            "2024-12-25 10:30:09.755263: Desired fold for training: 0\n",
            "2024-12-25 10:30:09.758521: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 10:30:09.762032: predicting BraTS2021_00000\n",
            "2024-12-25 10:30:09.801000: BraTS2021_00000, shape torch.Size([4, 146, 171, 136]), rank 0\n",
            "2024-12-25 10:30:23.200866: predicting BraTS2021_00011\n",
            "2024-12-25 10:30:23.253337: BraTS2021_00011, shape torch.Size([4, 142, 166, 141]), rank 0\n",
            "2024-12-25 10:30:24.260551: predicting BraTS2021_00017\n",
            "2024-12-25 10:30:24.289345: BraTS2021_00017, shape torch.Size([4, 138, 174, 147]), rank 0\n",
            "2024-12-25 10:30:33.422244: Validation complete\n",
            "2024-12-25 10:30:33.427578: Mean Validation Dice:  0.6440483526980835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 3d_fullres 1  -tr nnUNetTrainer_10epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNKuVfDrXzu_",
        "outputId": "111fc478-3df1-4f43-f424-e515eecc9bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 10:31:48.909037: do_dummy_2d_data_aug: False\n",
            "2024-12-25 10:31:48.914653: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 10:31:48.918979: The split file contains 5 splits.\n",
            "2024-12-25 10:31:48.921430: Desired fold for training: 1\n",
            "2024-12-25 10:31:48.923274: This split has 12 training and 3 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-12-25 10:31:57.125409: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 160, 112], 'median_image_size_in_voxels': [138.0, 174.0, 136.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 174, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3477.0, 'mean': 1033.44775390625, 'median': 913.0, 'min': 75.0, 'percentile_00_5': 212.0, 'percentile_99_5': 2637.0, 'std': 484.8674011230469}, '1': {'max': 10061.0, 'mean': 2287.951416015625, 'median': 2029.0, 'min': 14.0, 'percentile_00_5': 686.0, 'percentile_99_5': 6725.0, 'std': 1055.456298828125}, '2': {'max': 2343.0, 'mean': 790.7552490234375, 'median': 771.0, 'min': 13.0, 'percentile_00_5': 89.0, 'percentile_99_5': 1783.0, 'std': 305.4101867675781}, '3': {'max': 4050.0, 'mean': 1813.7210693359375, 'median': 1795.0, 'min': 44.0, 'percentile_00_5': 471.0, 'percentile_99_5': 3388.0, 'std': 624.7869262695312}}} \n",
            "\n",
            "2024-12-25 10:31:58.924377: unpacking dataset...\n",
            "2024-12-25 10:32:06.777136: unpacking done...\n",
            "2024-12-25 10:32:06.810823: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-12-25 10:32:06.823222: \n",
            "2024-12-25 10:32:06.825862: Epoch 0\n",
            "2024-12-25 10:32:06.828051: Current learning rate: 0.01\n",
            "2024-12-25 10:34:27.102466: train_loss -0.4357\n",
            "2024-12-25 10:34:27.111862: val_loss -0.3298\n",
            "2024-12-25 10:34:27.122159: Pseudo dice [0.6967, 0.1483, 0.6488]\n",
            "2024-12-25 10:34:27.131727: Epoch time: 140.28 s\n",
            "2024-12-25 10:34:27.140153: Yayy! New best EMA pseudo Dice: 0.4979\n",
            "2024-12-25 10:34:29.633522: \n",
            "2024-12-25 10:34:29.636446: Epoch 1\n",
            "2024-12-25 10:34:29.638679: Current learning rate: 0.0091\n",
            "2024-12-25 10:36:19.409243: train_loss -0.7383\n",
            "2024-12-25 10:36:19.416021: val_loss -0.4237\n",
            "2024-12-25 10:36:19.423528: Pseudo dice [0.8373, 0.3405, 0.7155]\n",
            "2024-12-25 10:36:19.444953: Epoch time: 109.78 s\n",
            "2024-12-25 10:36:19.452657: Yayy! New best EMA pseudo Dice: 0.5112\n",
            "2024-12-25 10:36:22.326626: \n",
            "2024-12-25 10:36:22.329660: Epoch 2\n",
            "2024-12-25 10:36:22.332007: Current learning rate: 0.00818\n",
            "2024-12-25 10:38:06.437773: train_loss -0.7846\n",
            "2024-12-25 10:38:06.457817: val_loss -0.3724\n",
            "2024-12-25 10:38:06.466370: Pseudo dice [0.8071, 0.2512, 0.6803]\n",
            "2024-12-25 10:38:06.496542: Epoch time: 104.11 s\n",
            "2024-12-25 10:38:06.507795: Yayy! New best EMA pseudo Dice: 0.5181\n",
            "2024-12-25 10:38:10.132791: \n",
            "2024-12-25 10:38:10.136582: Epoch 3\n",
            "2024-12-25 10:38:10.140160: Current learning rate: 0.00725\n",
            "2024-12-25 10:39:56.888198: train_loss -0.8327\n",
            "2024-12-25 10:39:56.897340: val_loss -0.5565\n",
            "2024-12-25 10:39:56.905366: Pseudo dice [0.873, 0.4856, 0.6019]\n",
            "2024-12-25 10:39:56.912277: Epoch time: 106.76 s\n",
            "2024-12-25 10:39:56.918496: Yayy! New best EMA pseudo Dice: 0.5316\n",
            "2024-12-25 10:39:59.619369: \n",
            "2024-12-25 10:39:59.622577: Epoch 4\n",
            "2024-12-25 10:39:59.625773: Current learning rate: 0.00631\n",
            "2024-12-25 10:41:35.290950: train_loss -0.8478\n",
            "2024-12-25 10:41:35.296356: val_loss -0.5872\n",
            "2024-12-25 10:41:35.303697: Pseudo dice [0.8917, 0.4852, 0.564]\n",
            "2024-12-25 10:41:35.309393: Epoch time: 95.67 s\n",
            "2024-12-25 10:41:35.314420: Yayy! New best EMA pseudo Dice: 0.5431\n",
            "2024-12-25 10:41:38.365347: \n",
            "2024-12-25 10:41:38.985383: Epoch 5\n",
            "2024-12-25 10:41:38.989606: Current learning rate: 0.00536\n",
            "2024-12-25 10:43:24.041210: train_loss -0.865\n",
            "2024-12-25 10:43:24.051243: val_loss -0.5117\n",
            "2024-12-25 10:43:24.057110: Pseudo dice [0.8913, 0.4424, 0.5576]\n",
            "2024-12-25 10:43:24.066996: Epoch time: 105.68 s\n",
            "2024-12-25 10:43:24.075291: Yayy! New best EMA pseudo Dice: 0.5519\n",
            "2024-12-25 10:43:26.911068: \n",
            "2024-12-25 10:43:26.913948: Epoch 6\n",
            "2024-12-25 10:43:26.917084: Current learning rate: 0.00438\n",
            "2024-12-25 10:45:03.220457: train_loss -0.8834\n",
            "2024-12-25 10:45:03.226843: val_loss -0.5156\n",
            "2024-12-25 10:45:03.233328: Pseudo dice [0.8519, 0.4563, 0.5854]\n",
            "2024-12-25 10:45:03.239869: Epoch time: 96.31 s\n",
            "2024-12-25 10:45:03.245755: Yayy! New best EMA pseudo Dice: 0.5598\n",
            "2024-12-25 10:45:06.841166: \n",
            "2024-12-25 10:45:06.844291: Epoch 7\n",
            "2024-12-25 10:45:06.847958: Current learning rate: 0.00338\n",
            "2024-12-25 10:46:51.435844: train_loss -0.8697\n",
            "2024-12-25 10:46:51.442687: val_loss -0.6019\n",
            "2024-12-25 10:46:51.449022: Pseudo dice [0.8892, 0.5007, 0.5381]\n",
            "2024-12-25 10:46:51.455350: Epoch time: 104.6 s\n",
            "2024-12-25 10:46:51.461286: Yayy! New best EMA pseudo Dice: 0.5681\n",
            "2024-12-25 10:46:54.629434: \n",
            "2024-12-25 10:46:54.632974: Epoch 8\n",
            "2024-12-25 10:46:54.636016: Current learning rate: 0.00235\n",
            "2024-12-25 10:48:31.542190: train_loss -0.877\n",
            "2024-12-25 10:48:31.552383: val_loss -0.5687\n",
            "2024-12-25 10:48:31.559300: Pseudo dice [0.8852, 0.4316, 0.609]\n",
            "2024-12-25 10:48:31.566906: Epoch time: 96.91 s\n",
            "2024-12-25 10:48:31.573618: Yayy! New best EMA pseudo Dice: 0.5755\n",
            "2024-12-25 10:48:34.527932: \n",
            "2024-12-25 10:48:34.546369: Epoch 9\n",
            "2024-12-25 10:48:34.548911: Current learning rate: 0.00126\n",
            "2024-12-25 10:50:14.516881: train_loss -0.888\n",
            "2024-12-25 10:50:14.523305: val_loss -0.4962\n",
            "2024-12-25 10:50:14.535392: Pseudo dice [0.883, 0.3839, 0.6237]\n",
            "2024-12-25 10:50:14.545265: Epoch time: 99.99 s\n",
            "2024-12-25 10:50:14.555078: Yayy! New best EMA pseudo Dice: 0.5809\n",
            "2024-12-25 10:50:18.217949: Training done.\n",
            "2024-12-25 10:50:18.418763: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 10:50:18.442574: The split file contains 5 splits.\n",
            "2024-12-25 10:50:18.449701: Desired fold for training: 1\n",
            "2024-12-25 10:50:18.453991: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 10:50:18.459369: predicting BraTS2021_00005\n",
            "2024-12-25 10:50:18.499819: BraTS2021_00005, shape torch.Size([4, 136, 161, 134]), rank 0\n",
            "2024-12-25 10:50:31.466788: predicting BraTS2021_00009\n",
            "2024-12-25 10:50:31.493039: BraTS2021_00009, shape torch.Size([4, 132, 167, 135]), rank 0\n",
            "2024-12-25 10:50:32.488644: predicting BraTS2021_00012\n",
            "2024-12-25 10:50:32.514593: BraTS2021_00012, shape torch.Size([4, 141, 178, 143]), rank 0\n",
            "2024-12-25 10:50:42.179485: Validation complete\n",
            "2024-12-25 10:50:42.182140: Mean Validation Dice:  0.6772904566921517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 3d_fullres 2  -tr nnUNetTrainer_10epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezMQXv9pcZyp",
        "outputId": "ee3b4a95-1669-40dc-fc32-f1ff765828c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 10:51:52.984469: do_dummy_2d_data_aug: False\n",
            "2024-12-25 10:51:52.989022: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 10:51:52.993071: The split file contains 5 splits.\n",
            "2024-12-25 10:51:52.995322: Desired fold for training: 2\n",
            "2024-12-25 10:51:52.997142: This split has 12 training and 3 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-12-25 10:52:03.516403: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 160, 112], 'median_image_size_in_voxels': [138.0, 174.0, 136.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 174, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3477.0, 'mean': 1033.44775390625, 'median': 913.0, 'min': 75.0, 'percentile_00_5': 212.0, 'percentile_99_5': 2637.0, 'std': 484.8674011230469}, '1': {'max': 10061.0, 'mean': 2287.951416015625, 'median': 2029.0, 'min': 14.0, 'percentile_00_5': 686.0, 'percentile_99_5': 6725.0, 'std': 1055.456298828125}, '2': {'max': 2343.0, 'mean': 790.7552490234375, 'median': 771.0, 'min': 13.0, 'percentile_00_5': 89.0, 'percentile_99_5': 1783.0, 'std': 305.4101867675781}, '3': {'max': 4050.0, 'mean': 1813.7210693359375, 'median': 1795.0, 'min': 44.0, 'percentile_00_5': 471.0, 'percentile_99_5': 3388.0, 'std': 624.7869262695312}}} \n",
            "\n",
            "2024-12-25 10:52:05.439346: unpacking dataset...\n",
            "2024-12-25 10:52:13.949808: unpacking done...\n",
            "2024-12-25 10:52:13.970381: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-12-25 10:52:13.983483: \n",
            "2024-12-25 10:52:13.986160: Epoch 0\n",
            "2024-12-25 10:52:13.988267: Current learning rate: 0.01\n",
            "2024-12-25 10:54:32.415581: train_loss -0.3861\n",
            "2024-12-25 10:54:32.421511: val_loss -0.6606\n",
            "2024-12-25 10:54:32.427325: Pseudo dice [0.894, 0.627, 0.6374]\n",
            "2024-12-25 10:54:32.432384: Epoch time: 138.43 s\n",
            "2024-12-25 10:54:32.438505: Yayy! New best EMA pseudo Dice: 0.7194\n",
            "2024-12-25 10:54:35.137747: \n",
            "2024-12-25 10:54:35.140745: Epoch 1\n",
            "2024-12-25 10:54:35.143224: Current learning rate: 0.0091\n",
            "2024-12-25 10:56:08.758824: train_loss -0.665\n",
            "2024-12-25 10:56:08.766795: val_loss -0.7278\n",
            "2024-12-25 10:56:08.776733: Pseudo dice [0.8913, 0.7184, 0.7103]\n",
            "2024-12-25 10:56:08.791135: Epoch time: 93.62 s\n",
            "2024-12-25 10:56:08.801682: Yayy! New best EMA pseudo Dice: 0.7248\n",
            "2024-12-25 10:56:11.537188: \n",
            "2024-12-25 10:56:11.540267: Epoch 2\n",
            "2024-12-25 10:56:11.543365: Current learning rate: 0.00818\n",
            "2024-12-25 10:57:57.568161: train_loss -0.7469\n",
            "2024-12-25 10:57:57.578890: val_loss -0.7456\n",
            "2024-12-25 10:57:57.587584: Pseudo dice [0.9019, 0.7511, 0.7285]\n",
            "2024-12-25 10:57:57.613464: Epoch time: 106.03 s\n",
            "2024-12-25 10:57:57.623118: Yayy! New best EMA pseudo Dice: 0.7317\n",
            "2024-12-25 10:58:01.329684: \n",
            "2024-12-25 10:58:01.332597: Epoch 3\n",
            "2024-12-25 10:58:01.335257: Current learning rate: 0.00725\n",
            "2024-12-25 10:59:40.498906: train_loss -0.7819\n",
            "2024-12-25 10:59:40.505548: val_loss -0.794\n",
            "2024-12-25 10:59:40.512023: Pseudo dice [0.9055, 0.8518, 0.7702]\n",
            "2024-12-25 10:59:40.517122: Epoch time: 99.17 s\n",
            "2024-12-25 10:59:40.523064: Yayy! New best EMA pseudo Dice: 0.7428\n",
            "2024-12-25 10:59:43.514412: \n",
            "2024-12-25 10:59:43.517334: Epoch 4\n",
            "2024-12-25 10:59:43.520360: Current learning rate: 0.00631\n",
            "2024-12-25 11:01:21.856201: train_loss -0.8173\n",
            "2024-12-25 11:01:21.864264: val_loss -0.7307\n",
            "2024-12-25 11:01:21.868884: Pseudo dice [0.9114, 0.7255, 0.6967]\n",
            "2024-12-25 11:01:21.876780: Epoch time: 98.34 s\n",
            "2024-12-25 11:01:21.882987: Yayy! New best EMA pseudo Dice: 0.7463\n",
            "2024-12-25 11:01:25.046890: \n",
            "2024-12-25 11:01:25.050503: Epoch 5\n",
            "2024-12-25 11:01:25.053921: Current learning rate: 0.00536\n",
            "2024-12-25 11:03:00.989767: train_loss -0.835\n",
            "2024-12-25 11:03:00.996635: val_loss -0.8102\n",
            "2024-12-25 11:03:01.005085: Pseudo dice [0.923, 0.8498, 0.7731]\n",
            "2024-12-25 11:03:01.011886: Epoch time: 95.94 s\n",
            "2024-12-25 11:03:01.018284: Yayy! New best EMA pseudo Dice: 0.7566\n",
            "2024-12-25 11:03:04.051679: \n",
            "2024-12-25 11:03:04.055049: Epoch 6\n",
            "2024-12-25 11:03:04.058713: Current learning rate: 0.00438\n",
            "2024-12-25 11:04:42.084002: train_loss -0.8378\n",
            "2024-12-25 11:04:42.092950: val_loss -0.8048\n",
            "2024-12-25 11:04:42.099425: Pseudo dice [0.9159, 0.8573, 0.7715]\n",
            "2024-12-25 11:04:42.109759: Epoch time: 98.03 s\n",
            "2024-12-25 11:04:42.116745: Yayy! New best EMA pseudo Dice: 0.7657\n",
            "2024-12-25 11:04:44.921486: \n",
            "2024-12-25 11:04:44.925189: Epoch 7\n",
            "2024-12-25 11:04:44.927941: Current learning rate: 0.00338\n",
            "2024-12-25 11:06:24.773250: train_loss -0.8432\n",
            "2024-12-25 11:06:24.780370: val_loss -0.83\n",
            "2024-12-25 11:06:24.787498: Pseudo dice [0.9234, 0.8801, 0.7889]\n",
            "2024-12-25 11:06:24.794691: Epoch time: 99.85 s\n",
            "2024-12-25 11:06:24.801066: Yayy! New best EMA pseudo Dice: 0.7756\n",
            "2024-12-25 11:06:27.887136: \n",
            "2024-12-25 11:06:27.890146: Epoch 8\n",
            "2024-12-25 11:06:27.893164: Current learning rate: 0.00235\n",
            "2024-12-25 11:08:09.877175: train_loss -0.8643\n",
            "2024-12-25 11:08:09.884088: val_loss -0.809\n",
            "2024-12-25 11:08:09.893522: Pseudo dice [0.9254, 0.8549, 0.7675]\n",
            "2024-12-25 11:08:09.898860: Epoch time: 101.99 s\n",
            "2024-12-25 11:08:09.903976: Yayy! New best EMA pseudo Dice: 0.7829\n",
            "2024-12-25 11:08:12.983403: \n",
            "2024-12-25 11:08:12.986441: Epoch 9\n",
            "2024-12-25 11:08:12.990144: Current learning rate: 0.00126\n",
            "2024-12-25 11:09:47.112769: train_loss -0.8583\n",
            "2024-12-25 11:09:47.120547: val_loss -0.818\n",
            "2024-12-25 11:09:47.130133: Pseudo dice [0.9176, 0.8594, 0.7791]\n",
            "2024-12-25 11:09:47.141081: Epoch time: 94.13 s\n",
            "2024-12-25 11:09:47.148583: Yayy! New best EMA pseudo Dice: 0.7898\n",
            "2024-12-25 11:09:50.463284: Training done.\n",
            "2024-12-25 11:09:50.693672: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 11:09:50.705563: The split file contains 5 splits.\n",
            "2024-12-25 11:09:50.710413: Desired fold for training: 2\n",
            "2024-12-25 11:09:50.713694: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 11:09:51.125703: predicting BraTS2021_00016\n",
            "2024-12-25 11:09:51.158735: BraTS2021_00016, shape torch.Size([4, 138, 172, 135]), rank 0\n",
            "2024-12-25 11:10:04.273604: predicting BraTS2021_00018\n",
            "2024-12-25 11:10:04.306756: BraTS2021_00018, shape torch.Size([4, 138, 177, 136]), rank 0\n",
            "2024-12-25 11:10:05.341690: predicting BraTS2021_00020\n",
            "2024-12-25 11:10:05.371158: BraTS2021_00020, shape torch.Size([4, 137, 182, 137]), rank 0\n",
            "2024-12-25 11:10:14.857488: Validation complete\n",
            "2024-12-25 11:10:14.860135: Mean Validation Dice:  0.8686338207962212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 3d_fullres 3  -tr nnUNetTrainer_10epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCoJLbjHhEx6",
        "outputId": "bb31d2e1-ad5a-42d2-dbed-603974d5bb13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 11:12:20.817568: do_dummy_2d_data_aug: False\n",
            "2024-12-25 11:12:20.822093: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 11:12:20.826035: The split file contains 5 splits.\n",
            "2024-12-25 11:12:20.828411: Desired fold for training: 3\n",
            "2024-12-25 11:12:20.830789: This split has 12 training and 3 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-12-25 11:12:40.384992: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 160, 112], 'median_image_size_in_voxels': [138.0, 174.0, 136.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 174, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3477.0, 'mean': 1033.44775390625, 'median': 913.0, 'min': 75.0, 'percentile_00_5': 212.0, 'percentile_99_5': 2637.0, 'std': 484.8674011230469}, '1': {'max': 10061.0, 'mean': 2287.951416015625, 'median': 2029.0, 'min': 14.0, 'percentile_00_5': 686.0, 'percentile_99_5': 6725.0, 'std': 1055.456298828125}, '2': {'max': 2343.0, 'mean': 790.7552490234375, 'median': 771.0, 'min': 13.0, 'percentile_00_5': 89.0, 'percentile_99_5': 1783.0, 'std': 305.4101867675781}, '3': {'max': 4050.0, 'mean': 1813.7210693359375, 'median': 1795.0, 'min': 44.0, 'percentile_00_5': 471.0, 'percentile_99_5': 3388.0, 'std': 624.7869262695312}}} \n",
            "\n",
            "2024-12-25 11:12:42.607722: unpacking dataset...\n",
            "2024-12-25 11:12:54.968402: unpacking done...\n",
            "2024-12-25 11:12:54.996702: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-12-25 11:12:55.014638: \n",
            "2024-12-25 11:12:55.034380: Epoch 0\n",
            "2024-12-25 11:12:55.038844: Current learning rate: 0.01\n",
            "2024-12-25 11:14:59.976350: train_loss -0.3954\n",
            "2024-12-25 11:14:59.999632: val_loss -0.6557\n",
            "2024-12-25 11:15:00.007179: Pseudo dice [0.7861, 0.7523, 0.8426]\n",
            "2024-12-25 11:15:00.015232: Epoch time: 124.96 s\n",
            "2024-12-25 11:15:00.024075: Yayy! New best EMA pseudo Dice: 0.7937\n",
            "2024-12-25 11:15:02.505635: \n",
            "2024-12-25 11:15:02.508674: Epoch 1\n",
            "2024-12-25 11:15:02.511910: Current learning rate: 0.0091\n",
            "2024-12-25 11:16:35.747335: train_loss -0.6594\n",
            "2024-12-25 11:16:35.756918: val_loss -0.5834\n",
            "2024-12-25 11:16:35.764893: Pseudo dice [0.8661, 0.8274, 0.8293]\n",
            "2024-12-25 11:16:35.786732: Epoch time: 93.24 s\n",
            "2024-12-25 11:16:35.795043: Yayy! New best EMA pseudo Dice: 0.7984\n",
            "2024-12-25 11:16:38.560467: \n",
            "2024-12-25 11:16:38.563664: Epoch 2\n",
            "2024-12-25 11:16:38.566968: Current learning rate: 0.00818\n",
            "2024-12-25 11:18:18.611987: train_loss -0.7507\n",
            "2024-12-25 11:18:18.619276: val_loss -0.5956\n",
            "2024-12-25 11:18:18.629560: Pseudo dice [0.8658, 0.7866, 0.8238]\n",
            "2024-12-25 11:18:18.639908: Epoch time: 100.05 s\n",
            "2024-12-25 11:18:18.649753: Yayy! New best EMA pseudo Dice: 0.8011\n",
            "2024-12-25 11:18:22.297749: \n",
            "2024-12-25 11:18:22.300586: Epoch 3\n",
            "2024-12-25 11:18:22.302716: Current learning rate: 0.00725\n",
            "2024-12-25 11:20:01.081853: train_loss -0.7977\n",
            "2024-12-25 11:20:01.090040: val_loss -0.6871\n",
            "2024-12-25 11:20:01.096178: Pseudo dice [0.8846, 0.9105, 0.8732]\n",
            "2024-12-25 11:20:01.103429: Epoch time: 98.79 s\n",
            "2024-12-25 11:20:01.108338: Yayy! New best EMA pseudo Dice: 0.8099\n",
            "2024-12-25 11:20:04.441977: \n",
            "2024-12-25 11:20:04.444917: Epoch 4\n",
            "2024-12-25 11:20:04.449104: Current learning rate: 0.00631\n",
            "2024-12-25 11:21:37.100737: train_loss -0.8103\n",
            "2024-12-25 11:21:37.107674: val_loss -0.7845\n",
            "2024-12-25 11:21:37.112821: Pseudo dice [0.9134, 0.8875, 0.887]\n",
            "2024-12-25 11:21:37.115795: Epoch time: 92.66 s\n",
            "2024-12-25 11:21:37.118482: Yayy! New best EMA pseudo Dice: 0.8185\n",
            "2024-12-25 11:21:39.975113: \n",
            "2024-12-25 11:21:39.977903: Epoch 5\n",
            "2024-12-25 11:21:39.980057: Current learning rate: 0.00536\n",
            "2024-12-25 11:23:16.961286: train_loss -0.828\n",
            "2024-12-25 11:23:16.975560: val_loss -0.7291\n",
            "2024-12-25 11:23:16.987391: Pseudo dice [0.8855, 0.9255, 0.8788]\n",
            "2024-12-25 11:23:16.996388: Epoch time: 96.99 s\n",
            "2024-12-25 11:23:17.007658: Yayy! New best EMA pseudo Dice: 0.8263\n",
            "2024-12-25 11:23:19.847859: \n",
            "2024-12-25 11:23:19.851003: Epoch 6\n",
            "2024-12-25 11:23:19.853461: Current learning rate: 0.00438\n",
            "2024-12-25 11:25:01.170288: train_loss -0.8345\n",
            "2024-12-25 11:25:01.179538: val_loss -0.6003\n",
            "2024-12-25 11:25:01.188012: Pseudo dice [0.8896, 0.8615, 0.8459]\n",
            "2024-12-25 11:25:01.229402: Epoch time: 101.32 s\n",
            "2024-12-25 11:25:01.239716: Yayy! New best EMA pseudo Dice: 0.8303\n",
            "2024-12-25 11:25:04.167371: \n",
            "2024-12-25 11:25:04.170405: Epoch 7\n",
            "2024-12-25 11:25:04.172651: Current learning rate: 0.00338\n",
            "2024-12-25 11:26:44.510138: train_loss -0.841\n",
            "2024-12-25 11:26:44.524169: val_loss -0.6469\n",
            "2024-12-25 11:26:44.532788: Pseudo dice [0.9063, 0.9056, 0.8785]\n",
            "2024-12-25 11:26:44.539785: Epoch time: 100.34 s\n",
            "2024-12-25 11:26:44.547763: Yayy! New best EMA pseudo Dice: 0.8369\n",
            "2024-12-25 11:26:47.573307: \n",
            "2024-12-25 11:26:47.576586: Epoch 8\n",
            "2024-12-25 11:26:47.579800: Current learning rate: 0.00235\n",
            "2024-12-25 11:28:24.429477: train_loss -0.8514\n",
            "2024-12-25 11:28:24.440079: val_loss -0.7827\n",
            "2024-12-25 11:28:24.446340: Pseudo dice [0.9192, 0.9326, 0.8847]\n",
            "2024-12-25 11:28:24.452797: Epoch time: 96.86 s\n",
            "2024-12-25 11:28:24.457940: Yayy! New best EMA pseudo Dice: 0.8445\n",
            "2024-12-25 11:28:27.398090: \n",
            "2024-12-25 11:28:27.401570: Epoch 9\n",
            "2024-12-25 11:28:27.405837: Current learning rate: 0.00126\n",
            "2024-12-25 11:30:06.403455: train_loss -0.8478\n",
            "2024-12-25 11:30:06.411194: val_loss -0.646\n",
            "2024-12-25 11:30:06.417887: Pseudo dice [0.9035, 0.9086, 0.8644]\n",
            "2024-12-25 11:30:06.423644: Epoch time: 99.01 s\n",
            "2024-12-25 11:30:06.429527: Yayy! New best EMA pseudo Dice: 0.8492\n",
            "2024-12-25 11:30:09.933249: Training done.\n",
            "2024-12-25 11:30:10.131479: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 11:30:10.138952: The split file contains 5 splits.\n",
            "2024-12-25 11:30:10.143108: Desired fold for training: 3\n",
            "2024-12-25 11:30:10.147872: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 11:30:10.169013: predicting BraTS2021_00006\n",
            "2024-12-25 11:30:10.209084: BraTS2021_00006, shape torch.Size([4, 136, 177, 134]), rank 0\n",
            "2024-12-25 11:30:23.319694: predicting BraTS2021_00014\n",
            "2024-12-25 11:30:23.354265: BraTS2021_00014, shape torch.Size([4, 126, 178, 136]), rank 0\n",
            "2024-12-25 11:30:23.946707: predicting BraTS2021_00019\n",
            "2024-12-25 11:30:23.977933: BraTS2021_00019, shape torch.Size([4, 143, 177, 142]), rank 0\n",
            "2024-12-25 11:30:33.349500: Validation complete\n",
            "2024-12-25 11:30:33.352181: Mean Validation Dice:  0.6615905196738606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 3d_fullres 4  -tr nnUNetTrainer_10epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP3XtctNmjPH",
        "outputId": "14aaadfb-a07b-4dc8-c115-1d46f9cccbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 11:36:14.064903: do_dummy_2d_data_aug: False\n",
            "2024-12-25 11:36:14.069352: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 11:36:14.083196: The split file contains 5 splits.\n",
            "2024-12-25 11:36:14.085528: Desired fold for training: 4\n",
            "2024-12-25 11:36:14.087441: This split has 12 training and 3 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-12-25 11:36:23.071433: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 160, 112], 'median_image_size_in_voxels': [138.0, 174.0, 136.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 174, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3477.0, 'mean': 1033.44775390625, 'median': 913.0, 'min': 75.0, 'percentile_00_5': 212.0, 'percentile_99_5': 2637.0, 'std': 484.8674011230469}, '1': {'max': 10061.0, 'mean': 2287.951416015625, 'median': 2029.0, 'min': 14.0, 'percentile_00_5': 686.0, 'percentile_99_5': 6725.0, 'std': 1055.456298828125}, '2': {'max': 2343.0, 'mean': 790.7552490234375, 'median': 771.0, 'min': 13.0, 'percentile_00_5': 89.0, 'percentile_99_5': 1783.0, 'std': 305.4101867675781}, '3': {'max': 4050.0, 'mean': 1813.7210693359375, 'median': 1795.0, 'min': 44.0, 'percentile_00_5': 471.0, 'percentile_99_5': 3388.0, 'std': 624.7869262695312}}} \n",
            "\n",
            "2024-12-25 11:36:25.010801: unpacking dataset...\n",
            "2024-12-25 11:36:33.422761: unpacking done...\n",
            "2024-12-25 11:36:33.444106: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-12-25 11:36:33.470586: \n",
            "2024-12-25 11:36:33.473259: Epoch 0\n",
            "2024-12-25 11:36:33.475548: Current learning rate: 0.01\n",
            "2024-12-25 11:38:51.190741: train_loss -0.3959\n",
            "2024-12-25 11:38:51.197356: val_loss -0.3945\n",
            "2024-12-25 11:38:51.202885: Pseudo dice [0.7088, 0.5919, 0.6515]\n",
            "2024-12-25 11:38:51.210347: Epoch time: 137.72 s\n",
            "2024-12-25 11:38:51.215270: Yayy! New best EMA pseudo Dice: 0.6507\n",
            "2024-12-25 11:38:53.804549: \n",
            "2024-12-25 11:38:53.807617: Epoch 1\n",
            "2024-12-25 11:38:53.810049: Current learning rate: 0.0091\n",
            "2024-12-25 11:40:32.283183: train_loss -0.7168\n",
            "2024-12-25 11:40:32.291863: val_loss -0.4981\n",
            "2024-12-25 11:40:32.300867: Pseudo dice [0.7511, 0.6549, 0.7257]\n",
            "2024-12-25 11:40:32.308062: Epoch time: 98.48 s\n",
            "2024-12-25 11:40:32.314898: Yayy! New best EMA pseudo Dice: 0.6567\n",
            "2024-12-25 11:40:35.332097: \n",
            "2024-12-25 11:40:35.334996: Epoch 2\n",
            "2024-12-25 11:40:35.338159: Current learning rate: 0.00818\n",
            "2024-12-25 11:42:14.668140: train_loss -0.763\n",
            "2024-12-25 11:42:14.674188: val_loss -0.4555\n",
            "2024-12-25 11:42:14.679735: Pseudo dice [0.7463, 0.7216, 0.679]\n",
            "2024-12-25 11:42:14.685160: Epoch time: 99.34 s\n",
            "2024-12-25 11:42:14.705956: Yayy! New best EMA pseudo Dice: 0.6626\n",
            "2024-12-25 11:42:17.807608: \n",
            "2024-12-25 11:42:17.810689: Epoch 3\n",
            "2024-12-25 11:42:17.813030: Current learning rate: 0.00725\n",
            "2024-12-25 11:43:54.937872: train_loss -0.8143\n",
            "2024-12-25 11:43:54.943434: val_loss -0.5042\n",
            "2024-12-25 11:43:54.948615: Pseudo dice [0.7568, 0.7554, 0.6965]\n",
            "2024-12-25 11:43:54.954244: Epoch time: 97.13 s\n",
            "2024-12-25 11:43:54.959493: Yayy! New best EMA pseudo Dice: 0.6699\n",
            "2024-12-25 11:43:57.751709: \n",
            "2024-12-25 11:43:57.754714: Epoch 4\n",
            "2024-12-25 11:43:57.757059: Current learning rate: 0.00631\n",
            "2024-12-25 11:45:37.682930: train_loss -0.8198\n",
            "2024-12-25 11:45:37.688688: val_loss -0.5186\n",
            "2024-12-25 11:45:37.693141: Pseudo dice [0.7586, 0.7852, 0.7227]\n",
            "2024-12-25 11:45:37.699764: Epoch time: 99.93 s\n",
            "2024-12-25 11:45:37.706695: Yayy! New best EMA pseudo Dice: 0.6785\n",
            "2024-12-25 11:45:40.702508: \n",
            "2024-12-25 11:45:40.705876: Epoch 5\n",
            "2024-12-25 11:45:40.708261: Current learning rate: 0.00536\n",
            "2024-12-25 11:47:19.698724: train_loss -0.8417\n",
            "2024-12-25 11:47:19.704543: val_loss -0.5694\n",
            "2024-12-25 11:47:19.710412: Pseudo dice [0.7995, 0.7962, 0.7699]\n",
            "2024-12-25 11:47:19.716032: Epoch time: 99.0 s\n",
            "2024-12-25 11:47:19.721688: Yayy! New best EMA pseudo Dice: 0.6895\n",
            "2024-12-25 11:47:22.690153: \n",
            "2024-12-25 11:47:22.693321: Epoch 6\n",
            "2024-12-25 11:47:22.697249: Current learning rate: 0.00438\n",
            "2024-12-25 11:49:03.525145: train_loss -0.8576\n",
            "2024-12-25 11:49:03.530207: val_loss -0.5489\n",
            "2024-12-25 11:49:03.535202: Pseudo dice [0.7809, 0.7968, 0.7526]\n",
            "2024-12-25 11:49:03.540147: Epoch time: 100.84 s\n",
            "2024-12-25 11:49:03.545452: Yayy! New best EMA pseudo Dice: 0.6982\n",
            "2024-12-25 11:49:06.531653: \n",
            "2024-12-25 11:49:06.535028: Epoch 7\n",
            "2024-12-25 11:49:06.538813: Current learning rate: 0.00338\n",
            "2024-12-25 11:50:45.964985: train_loss -0.8547\n",
            "2024-12-25 11:50:45.970496: val_loss -0.5874\n",
            "2024-12-25 11:50:45.975233: Pseudo dice [0.7591, 0.7795, 0.7243]\n",
            "2024-12-25 11:50:45.980188: Epoch time: 99.43 s\n",
            "2024-12-25 11:50:45.988828: Yayy! New best EMA pseudo Dice: 0.7038\n",
            "2024-12-25 11:50:49.001581: \n",
            "2024-12-25 11:50:49.004543: Epoch 8\n",
            "2024-12-25 11:50:49.006708: Current learning rate: 0.00235\n",
            "2024-12-25 11:52:29.913754: \n",
            "2024-12-25 11:52:29.916795: Epoch 9\n",
            "2024-12-25 11:52:29.942328: Current learning rate: 0.00126\n",
            "2024-12-25 11:54:07.365249: train_loss -0.8716\n",
            "2024-12-25 11:54:07.372056: val_loss -0.5777\n",
            "2024-12-25 11:54:07.375140: Pseudo dice [0.7564, 0.7605, 0.7098]\n",
            "2024-12-25 11:54:07.377611: Epoch time: 97.45 s\n",
            "2024-12-25 11:54:07.380121: Yayy! New best EMA pseudo Dice: 0.7127\n",
            "2024-12-25 11:54:11.105337: Training done.\n",
            "2024-12-25 11:54:11.222972: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 11:54:11.231595: The split file contains 5 splits.\n",
            "2024-12-25 11:54:11.235208: Desired fold for training: 4\n",
            "2024-12-25 11:54:11.238142: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 11:54:11.241226: predicting BraTS2021_00002\n",
            "2024-12-25 11:54:11.280158: BraTS2021_00002, shape torch.Size([4, 135, 174, 133]), rank 0\n",
            "2024-12-25 11:54:23.442997: predicting BraTS2021_00003\n",
            "2024-12-25 11:54:23.484445: BraTS2021_00003, shape torch.Size([4, 140, 178, 141]), rank 0\n",
            "2024-12-25 11:54:24.514005: predicting BraTS2021_00008\n",
            "2024-12-25 11:54:24.565170: BraTS2021_00008, shape torch.Size([4, 133, 168, 142]), rank 0\n",
            "2024-12-25 11:54:33.717234: Validation complete\n",
            "2024-12-25 11:54:33.720057: Mean Validation Dice:  0.7101802526659053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 2d 0  -tr nnUNetTrainer_10epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA8dgtnmryq-",
        "outputId": "c055685d-6fb6-4469-8f55-b01a21665c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 11:59:13.008808: do_dummy_2d_data_aug: False\n",
            "2024-12-25 11:59:13.357970: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 11:59:13.363552: The split file contains 5 splits.\n",
            "2024-12-25 11:59:13.365916: Desired fold for training: 0\n",
            "2024-12-25 11:59:13.367862: This split has 12 training and 3 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-12-25 11:59:40.814741: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 2d\n",
            " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 80, 'patch_size': [192, 160], 'median_image_size_in_voxels': [174.0, 136.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 174, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3477.0, 'mean': 1033.44775390625, 'median': 913.0, 'min': 75.0, 'percentile_00_5': 212.0, 'percentile_99_5': 2637.0, 'std': 484.8674011230469}, '1': {'max': 10061.0, 'mean': 2287.951416015625, 'median': 2029.0, 'min': 14.0, 'percentile_00_5': 686.0, 'percentile_99_5': 6725.0, 'std': 1055.456298828125}, '2': {'max': 2343.0, 'mean': 790.7552490234375, 'median': 771.0, 'min': 13.0, 'percentile_00_5': 89.0, 'percentile_99_5': 1783.0, 'std': 305.4101867675781}, '3': {'max': 4050.0, 'mean': 1813.7210693359375, 'median': 1795.0, 'min': 44.0, 'percentile_00_5': 471.0, 'percentile_99_5': 3388.0, 'std': 624.7869262695312}}} \n",
            "\n",
            "2024-12-25 11:59:42.472399: unpacking dataset...\n",
            "2024-12-25 11:59:51.136448: unpacking done...\n",
            "2024-12-25 11:59:51.193446: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-12-25 11:59:51.213923: \n",
            "2024-12-25 11:59:51.220114: Epoch 0\n",
            "2024-12-25 11:59:51.225051: Current learning rate: 0.01\n",
            "2024-12-25 12:04:32.403710: train_loss -0.4213\n",
            "2024-12-25 12:04:32.412123: val_loss -0.7625\n",
            "2024-12-25 12:04:32.418391: Pseudo dice [0.8738, 0.7083, 0.8387]\n",
            "2024-12-25 12:04:32.424828: Epoch time: 281.19 s\n",
            "2024-12-25 12:04:32.432402: Yayy! New best EMA pseudo Dice: 0.807\n",
            "2024-12-25 12:04:35.818215: \n",
            "2024-12-25 12:04:35.825504: Epoch 1\n",
            "2024-12-25 12:04:35.833605: Current learning rate: 0.0091\n",
            "2024-12-25 12:08:28.662026: train_loss -0.8568\n",
            "2024-12-25 12:08:28.672637: val_loss -0.8192\n",
            "2024-12-25 12:08:28.679878: Pseudo dice [0.8767, 0.8416, 0.8522]\n",
            "2024-12-25 12:08:28.688978: Epoch time: 232.85 s\n",
            "2024-12-25 12:08:28.694588: Yayy! New best EMA pseudo Dice: 0.8119\n",
            "2024-12-25 12:08:31.941160: \n",
            "2024-12-25 12:08:31.955625: Epoch 2\n",
            "2024-12-25 12:08:31.964718: Current learning rate: 0.00818\n",
            "2024-12-25 12:12:23.860908: train_loss -0.9031\n",
            "2024-12-25 12:12:23.868810: val_loss -0.848\n",
            "2024-12-25 12:12:23.877342: Pseudo dice [0.8935, 0.8845, 0.8538]\n",
            "2024-12-25 12:12:23.883363: Epoch time: 231.92 s\n",
            "2024-12-25 12:12:23.889381: Yayy! New best EMA pseudo Dice: 0.8185\n",
            "2024-12-25 12:12:27.079600: \n",
            "2024-12-25 12:12:27.087069: Epoch 3\n",
            "2024-12-25 12:12:27.093356: Current learning rate: 0.00725\n",
            "2024-12-25 12:16:20.659834: train_loss -0.9182\n",
            "2024-12-25 12:16:20.669832: val_loss -0.8512\n",
            "2024-12-25 12:16:20.678244: Pseudo dice [0.8939, 0.8866, 0.8538]\n",
            "2024-12-25 12:16:20.683500: Epoch time: 233.58 s\n",
            "2024-12-25 12:16:20.688646: Yayy! New best EMA pseudo Dice: 0.8244\n",
            "2024-12-25 12:16:23.958806: \n",
            "2024-12-25 12:16:23.967073: Epoch 4\n",
            "2024-12-25 12:16:23.973547: Current learning rate: 0.00631\n",
            "2024-12-25 12:20:14.937155: train_loss -0.9261\n",
            "2024-12-25 12:20:14.946244: val_loss -0.8792\n",
            "2024-12-25 12:20:14.968045: Pseudo dice [0.9091, 0.9183, 0.8854]\n",
            "2024-12-25 12:20:14.976887: Epoch time: 230.98 s\n",
            "2024-12-25 12:20:14.982965: Yayy! New best EMA pseudo Dice: 0.8324\n",
            "2024-12-25 12:20:18.232166: \n",
            "2024-12-25 12:20:18.242781: Epoch 5\n",
            "2024-12-25 12:20:18.255594: Current learning rate: 0.00536\n",
            "2024-12-25 12:24:07.478977: train_loss -0.9315\n",
            "2024-12-25 12:24:07.489998: val_loss -0.9024\n",
            "2024-12-25 12:24:07.499646: Pseudo dice [0.9226, 0.9417, 0.9131]\n",
            "2024-12-25 12:24:07.507709: Epoch time: 229.25 s\n",
            "2024-12-25 12:24:07.511921: Yayy! New best EMA pseudo Dice: 0.8418\n",
            "2024-12-25 12:24:10.526995: \n",
            "2024-12-25 12:24:10.536029: Epoch 6\n",
            "2024-12-25 12:24:10.543764: Current learning rate: 0.00438\n",
            "2024-12-25 12:28:02.675900: train_loss -0.9349\n",
            "2024-12-25 12:28:02.682815: val_loss -0.901\n",
            "2024-12-25 12:28:02.687848: Pseudo dice [0.92, 0.9396, 0.91]\n",
            "2024-12-25 12:28:02.694655: Epoch time: 232.15 s\n",
            "2024-12-25 12:28:02.701252: Yayy! New best EMA pseudo Dice: 0.8499\n",
            "2024-12-25 12:28:05.682950: \n",
            "2024-12-25 12:28:05.692071: Epoch 7\n",
            "2024-12-25 12:28:05.700637: Current learning rate: 0.00338\n",
            "2024-12-25 12:31:56.181189: train_loss -0.9374\n",
            "2024-12-25 12:31:56.189483: val_loss -0.8971\n",
            "2024-12-25 12:31:56.200009: Pseudo dice [0.9178, 0.9371, 0.9048]\n",
            "2024-12-25 12:31:56.206712: Epoch time: 230.5 s\n",
            "2024-12-25 12:31:56.214029: Yayy! New best EMA pseudo Dice: 0.8569\n",
            "2024-12-25 12:31:59.174801: \n",
            "2024-12-25 12:31:59.184575: Epoch 8\n",
            "2024-12-25 12:31:59.193605: Current learning rate: 0.00235\n",
            "2024-12-25 12:35:53.256572: train_loss -0.9387\n",
            "2024-12-25 12:35:53.264925: val_loss -0.9095\n",
            "2024-12-25 12:35:53.273613: Pseudo dice [0.9242, 0.9481, 0.9197]\n",
            "2024-12-25 12:35:53.280263: Epoch time: 234.08 s\n",
            "2024-12-25 12:35:53.303624: Yayy! New best EMA pseudo Dice: 0.8643\n",
            "2024-12-25 12:35:56.286507: \n",
            "2024-12-25 12:35:56.295460: Epoch 9\n",
            "2024-12-25 12:35:56.300236: Current learning rate: 0.00126\n",
            "2024-12-25 12:39:50.520141: train_loss -0.94\n",
            "2024-12-25 12:39:50.529793: val_loss -0.8983\n",
            "2024-12-25 12:39:50.538725: Pseudo dice [0.9237, 0.9331, 0.9029]\n",
            "2024-12-25 12:39:50.546010: Epoch time: 234.24 s\n",
            "2024-12-25 12:39:50.552674: Yayy! New best EMA pseudo Dice: 0.8698\n",
            "2024-12-25 12:39:54.839106: Training done.\n",
            "2024-12-25 12:39:54.974088: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 12:39:55.000275: The split file contains 5 splits.\n",
            "2024-12-25 12:39:55.004597: Desired fold for training: 0\n",
            "2024-12-25 12:39:55.010449: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 12:39:55.015453: predicting BraTS2021_00000\n",
            "2024-12-25 12:39:55.036560: BraTS2021_00000, shape torch.Size([4, 146, 171, 136]), rank 0\n",
            "2024-12-25 12:40:18.142179: predicting BraTS2021_00011\n",
            "2024-12-25 12:40:18.164993: BraTS2021_00011, shape torch.Size([4, 142, 166, 141]), rank 0\n",
            "2024-12-25 12:40:20.633152: predicting BraTS2021_00017\n",
            "2024-12-25 12:40:20.652072: BraTS2021_00017, shape torch.Size([4, 138, 174, 147]), rank 0\n",
            "2024-12-25 12:40:31.458171: Validation complete\n",
            "2024-12-25 12:40:31.460809: Mean Validation Dice:  0.7981231770406132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 2d 1  -tr nnUNetTrainer_10epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taJv9knO1ZdQ",
        "outputId": "255bb974-f41e-4fc9-ca98-578fab932967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 12:41:05.174538: do_dummy_2d_data_aug: False\n",
            "2024-12-25 12:41:05.180854: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 12:41:05.184988: The split file contains 5 splits.\n",
            "2024-12-25 12:41:05.187233: Desired fold for training: 1\n",
            "2024-12-25 12:41:05.189139: This split has 12 training and 3 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-12-25 12:41:30.376915: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 2d\n",
            " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 80, 'patch_size': [192, 160], 'median_image_size_in_voxels': [174.0, 136.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 174, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3477.0, 'mean': 1033.44775390625, 'median': 913.0, 'min': 75.0, 'percentile_00_5': 212.0, 'percentile_99_5': 2637.0, 'std': 484.8674011230469}, '1': {'max': 10061.0, 'mean': 2287.951416015625, 'median': 2029.0, 'min': 14.0, 'percentile_00_5': 686.0, 'percentile_99_5': 6725.0, 'std': 1055.456298828125}, '2': {'max': 2343.0, 'mean': 790.7552490234375, 'median': 771.0, 'min': 13.0, 'percentile_00_5': 89.0, 'percentile_99_5': 1783.0, 'std': 305.4101867675781}, '3': {'max': 4050.0, 'mean': 1813.7210693359375, 'median': 1795.0, 'min': 44.0, 'percentile_00_5': 471.0, 'percentile_99_5': 3388.0, 'std': 624.7869262695312}}} \n",
            "\n",
            "2024-12-25 12:41:31.900906: unpacking dataset...\n",
            "2024-12-25 12:41:40.887203: unpacking done...\n",
            "2024-12-25 12:41:40.936987: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-12-25 12:41:40.956851: \n",
            "2024-12-25 12:41:40.962655: Epoch 0\n",
            "2024-12-25 12:41:40.967204: Current learning rate: 0.01\n",
            "2024-12-25 12:45:42.786916: train_loss -0.4362\n",
            "2024-12-25 12:45:42.796699: val_loss -0.3955\n",
            "2024-12-25 12:45:42.809904: Pseudo dice [0.8033, 0.3864, 0.5112]\n",
            "2024-12-25 12:45:42.818662: Epoch time: 241.83 s\n",
            "2024-12-25 12:45:42.823738: Yayy! New best EMA pseudo Dice: 0.567\n",
            "2024-12-25 12:45:45.662220: \n",
            "2024-12-25 12:45:45.668224: Epoch 1\n",
            "2024-12-25 12:45:45.674828: Current learning rate: 0.0091\n",
            "2024-12-25 12:49:37.706910: train_loss -0.8778\n",
            "2024-12-25 12:49:37.718359: val_loss -0.5093\n",
            "2024-12-25 12:49:37.725445: Pseudo dice [0.8805, 0.3513, 0.6329]\n",
            "2024-12-25 12:49:37.736027: Epoch time: 232.05 s\n",
            "2024-12-25 12:49:37.743375: Yayy! New best EMA pseudo Dice: 0.5724\n",
            "2024-12-25 12:49:40.812788: \n",
            "2024-12-25 12:49:40.822944: Epoch 2\n",
            "2024-12-25 12:49:40.833528: Current learning rate: 0.00818\n",
            "2024-12-25 12:53:35.475206: train_loss -0.913\n",
            "2024-12-25 12:53:35.485234: val_loss -0.5124\n",
            "2024-12-25 12:53:35.497396: Pseudo dice [0.889, 0.3407, 0.6558]\n",
            "2024-12-25 12:53:35.508932: Epoch time: 234.66 s\n",
            "2024-12-25 12:53:35.519267: Yayy! New best EMA pseudo Dice: 0.578\n",
            "2024-12-25 12:53:38.569155: \n",
            "2024-12-25 12:53:38.576217: Epoch 3\n",
            "2024-12-25 12:53:38.583811: Current learning rate: 0.00725\n",
            "2024-12-25 12:57:29.041940: train_loss -0.9261\n",
            "2024-12-25 12:57:29.050709: val_loss -0.4945\n",
            "2024-12-25 12:57:29.059458: Pseudo dice [0.8846, 0.3831, 0.5539]\n",
            "2024-12-25 12:57:29.068685: Epoch time: 230.47 s\n",
            "2024-12-25 12:57:29.075714: Yayy! New best EMA pseudo Dice: 0.581\n",
            "2024-12-25 12:57:32.764331: \n",
            "2024-12-25 12:57:32.772911: Epoch 4\n",
            "2024-12-25 12:57:32.779762: Current learning rate: 0.00631\n",
            "2024-12-25 13:01:22.340582: train_loss -0.9327\n",
            "2024-12-25 13:01:22.361019: val_loss -0.5074\n",
            "2024-12-25 13:01:22.370794: Pseudo dice [0.8903, 0.4059, 0.5553]\n",
            "2024-12-25 13:01:22.376727: Epoch time: 229.58 s\n",
            "2024-12-25 13:01:22.382990: Yayy! New best EMA pseudo Dice: 0.5846\n",
            "2024-12-25 13:01:25.496969: \n",
            "2024-12-25 13:01:25.510216: Epoch 5\n",
            "2024-12-25 13:01:25.518448: Current learning rate: 0.00536\n",
            "2024-12-25 13:05:16.605972: train_loss -0.9365\n",
            "2024-12-25 13:05:16.613734: val_loss -0.4669\n",
            "2024-12-25 13:05:16.623029: Pseudo dice [0.8836, 0.3439, 0.5487]\n",
            "2024-12-25 13:05:16.628694: Epoch time: 231.11 s\n",
            "2024-12-25 13:05:16.633897: Yayy! New best EMA pseudo Dice: 0.5853\n",
            "2024-12-25 13:05:19.712525: \n",
            "2024-12-25 13:05:19.720782: Epoch 6\n",
            "2024-12-25 13:05:19.732703: Current learning rate: 0.00438\n",
            "2024-12-25 13:09:10.424025: train_loss -0.9399\n",
            "2024-12-25 13:09:10.441645: val_loss -0.5054\n",
            "2024-12-25 13:09:10.451664: Pseudo dice [0.8891, 0.4078, 0.5694]\n",
            "2024-12-25 13:09:10.458965: Epoch time: 230.71 s\n",
            "2024-12-25 13:09:10.464701: Yayy! New best EMA pseudo Dice: 0.589\n",
            "2024-12-25 13:09:13.386277: \n",
            "2024-12-25 13:09:13.395125: Epoch 7\n",
            "2024-12-25 13:09:13.402710: Current learning rate: 0.00338\n",
            "2024-12-25 13:13:04.919097: train_loss -0.9417\n",
            "2024-12-25 13:13:04.931949: val_loss -0.5273\n",
            "2024-12-25 13:13:04.939808: Pseudo dice [0.8928, 0.4392, 0.5751]\n",
            "2024-12-25 13:13:04.947471: Epoch time: 231.53 s\n",
            "2024-12-25 13:13:04.956481: Yayy! New best EMA pseudo Dice: 0.5937\n",
            "2024-12-25 13:13:07.945952: \n",
            "2024-12-25 13:13:07.953803: Epoch 8\n",
            "2024-12-25 13:13:07.965208: Current learning rate: 0.00235\n",
            "2024-12-25 13:16:58.554138: train_loss -0.9433\n",
            "2024-12-25 13:16:58.582362: val_loss -0.545\n",
            "2024-12-25 13:16:58.591792: Pseudo dice [0.9017, 0.4683, 0.5705]\n",
            "2024-12-25 13:16:58.599031: Epoch time: 230.61 s\n",
            "2024-12-25 13:16:58.605188: Yayy! New best EMA pseudo Dice: 0.599\n",
            "2024-12-25 13:17:01.576113: \n",
            "2024-12-25 13:17:01.585616: Epoch 9\n",
            "2024-12-25 13:17:01.592217: Current learning rate: 0.00126\n",
            "2024-12-25 13:20:53.077226: train_loss -0.944\n",
            "2024-12-25 13:20:53.082996: val_loss -0.521\n",
            "2024-12-25 13:20:53.089384: Pseudo dice [0.893, 0.4132, 0.5947]\n",
            "2024-12-25 13:20:53.094808: Epoch time: 231.5 s\n",
            "2024-12-25 13:20:53.101188: Yayy! New best EMA pseudo Dice: 0.6025\n",
            "2024-12-25 13:20:56.907919: Training done.\n",
            "2024-12-25 13:20:57.041600: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 13:20:57.062160: The split file contains 5 splits.\n",
            "2024-12-25 13:20:57.085223: Desired fold for training: 1\n",
            "2024-12-25 13:20:57.090695: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 13:20:57.095023: predicting BraTS2021_00005\n",
            "2024-12-25 13:20:57.117889: BraTS2021_00005, shape torch.Size([4, 136, 161, 134]), rank 0\n",
            "2024-12-25 13:21:11.025835: predicting BraTS2021_00009\n",
            "2024-12-25 13:21:11.050044: BraTS2021_00009, shape torch.Size([4, 132, 167, 135]), rank 0\n",
            "2024-12-25 13:21:13.311102: predicting BraTS2021_00012\n",
            "2024-12-25 13:21:13.328939: BraTS2021_00012, shape torch.Size([4, 141, 178, 143]), rank 0\n",
            "2024-12-25 13:21:23.984036: Validation complete\n",
            "2024-12-25 13:21:23.986568: Mean Validation Dice:  0.6004729778184222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 2d 2 -tr nnUNetTrainer_10epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ivp1Jz4-wZC",
        "outputId": "d54a2fd6-1b7d-4dd6-d667-d3751ce03afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 13:22:01.967202: do_dummy_2d_data_aug: False\n",
            "2024-12-25 13:22:01.972865: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 13:22:01.978359: The split file contains 5 splits.\n",
            "2024-12-25 13:22:01.980934: Desired fold for training: 2\n",
            "2024-12-25 13:22:01.983978: This split has 12 training and 3 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-12-25 13:22:27.159812: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 2d\n",
            " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 80, 'patch_size': [192, 160], 'median_image_size_in_voxels': [174.0, 136.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 174, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3477.0, 'mean': 1033.44775390625, 'median': 913.0, 'min': 75.0, 'percentile_00_5': 212.0, 'percentile_99_5': 2637.0, 'std': 484.8674011230469}, '1': {'max': 10061.0, 'mean': 2287.951416015625, 'median': 2029.0, 'min': 14.0, 'percentile_00_5': 686.0, 'percentile_99_5': 6725.0, 'std': 1055.456298828125}, '2': {'max': 2343.0, 'mean': 790.7552490234375, 'median': 771.0, 'min': 13.0, 'percentile_00_5': 89.0, 'percentile_99_5': 1783.0, 'std': 305.4101867675781}, '3': {'max': 4050.0, 'mean': 1813.7210693359375, 'median': 1795.0, 'min': 44.0, 'percentile_00_5': 471.0, 'percentile_99_5': 3388.0, 'std': 624.7869262695312}}} \n",
            "\n",
            "2024-12-25 13:22:28.537073: unpacking dataset...\n",
            "2024-12-25 13:22:37.145694: unpacking done...\n",
            "2024-12-25 13:22:37.188145: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-12-25 13:22:37.206052: \n",
            "2024-12-25 13:22:37.212537: Epoch 0\n",
            "2024-12-25 13:22:37.218026: Current learning rate: 0.01\n",
            "2024-12-25 13:26:38.116443: train_loss -0.454\n",
            "2024-12-25 13:26:38.123246: val_loss -0.746\n",
            "2024-12-25 13:26:38.128430: Pseudo dice [0.9029, 0.7824, 0.7389]\n",
            "2024-12-25 13:26:38.134549: Epoch time: 240.91 s\n",
            "2024-12-25 13:26:38.139590: Yayy! New best EMA pseudo Dice: 0.8081\n",
            "2024-12-25 13:26:40.705484: \n",
            "2024-12-25 13:26:40.712196: Epoch 1\n",
            "2024-12-25 13:26:40.719205: Current learning rate: 0.0091\n",
            "2024-12-25 13:30:34.527873: train_loss -0.8846\n",
            "2024-12-25 13:30:34.537361: val_loss -0.8086\n",
            "2024-12-25 13:30:34.545851: Pseudo dice [0.9351, 0.8519, 0.7826]\n",
            "2024-12-25 13:30:34.554395: Epoch time: 233.82 s\n",
            "2024-12-25 13:30:34.558597: Yayy! New best EMA pseudo Dice: 0.8129\n",
            "2024-12-25 13:30:37.280008: \n",
            "2024-12-25 13:30:37.288155: Epoch 2\n",
            "2024-12-25 13:30:37.294068: Current learning rate: 0.00818\n",
            "2024-12-25 13:34:28.666981: train_loss -0.9177\n",
            "2024-12-25 13:34:28.675895: val_loss -0.8154\n",
            "2024-12-25 13:34:28.698305: Pseudo dice [0.9377, 0.8494, 0.7903]\n",
            "2024-12-25 13:34:28.705945: Epoch time: 231.39 s\n",
            "2024-12-25 13:34:28.714347: Yayy! New best EMA pseudo Dice: 0.8175\n",
            "2024-12-25 13:34:31.635183: \n",
            "2024-12-25 13:34:31.641263: Epoch 3\n",
            "2024-12-25 13:34:31.647626: Current learning rate: 0.00725\n",
            "2024-12-25 13:38:22.679709: train_loss -0.9301\n",
            "2024-12-25 13:38:22.687032: val_loss -0.8114\n",
            "2024-12-25 13:38:22.693835: Pseudo dice [0.9384, 0.8444, 0.792]\n",
            "2024-12-25 13:38:22.701932: Epoch time: 231.05 s\n",
            "2024-12-25 13:38:22.709338: Yayy! New best EMA pseudo Dice: 0.8216\n",
            "2024-12-25 13:38:26.046784: \n",
            "2024-12-25 13:38:26.055765: Epoch 4\n",
            "2024-12-25 13:38:26.060815: Current learning rate: 0.00631\n",
            "2024-12-25 13:42:17.521241: train_loss -0.937\n",
            "2024-12-25 13:42:17.527738: val_loss -0.8058\n",
            "2024-12-25 13:42:17.532883: Pseudo dice [0.9339, 0.839, 0.7852]\n",
            "2024-12-25 13:42:17.549825: Epoch time: 231.48 s\n",
            "2024-12-25 13:42:17.562702: Yayy! New best EMA pseudo Dice: 0.8247\n",
            "2024-12-25 13:42:20.355281: \n",
            "2024-12-25 13:42:20.363692: Epoch 5\n",
            "2024-12-25 13:42:20.373018: Current learning rate: 0.00536\n",
            "2024-12-25 13:46:12.251952: train_loss -0.9411\n",
            "2024-12-25 13:46:12.260011: val_loss -0.7963\n",
            "2024-12-25 13:46:12.267629: Pseudo dice [0.9313, 0.8281, 0.7823]\n",
            "2024-12-25 13:46:12.292473: Epoch time: 231.9 s\n",
            "2024-12-25 13:46:12.300164: Yayy! New best EMA pseudo Dice: 0.827\n",
            "2024-12-25 13:46:15.131822: \n",
            "2024-12-25 13:46:15.141129: Epoch 6\n",
            "2024-12-25 13:46:15.148360: Current learning rate: 0.00438\n",
            "2024-12-25 13:50:07.966157: train_loss -0.944\n",
            "2024-12-25 13:50:07.973891: val_loss -0.7977\n",
            "2024-12-25 13:50:08.000823: Pseudo dice [0.9378, 0.8255, 0.7814]\n",
            "2024-12-25 13:50:08.008991: Epoch time: 232.84 s\n",
            "2024-12-25 13:50:08.017905: Yayy! New best EMA pseudo Dice: 0.8291\n",
            "2024-12-25 13:50:11.253162: \n",
            "2024-12-25 13:50:11.258599: Epoch 7\n",
            "2024-12-25 13:50:11.266300: Current learning rate: 0.00338\n",
            "2024-12-25 13:54:03.734603: train_loss -0.9455\n",
            "2024-12-25 13:54:03.744042: val_loss -0.7998\n",
            "2024-12-25 13:54:03.767984: Pseudo dice [0.9344, 0.8275, 0.7858]\n",
            "2024-12-25 13:54:03.777059: Epoch time: 232.48 s\n",
            "2024-12-25 13:54:03.783867: Yayy! New best EMA pseudo Dice: 0.8311\n",
            "2024-12-25 13:54:06.736250: \n",
            "2024-12-25 13:54:06.743802: Epoch 8\n",
            "2024-12-25 13:54:06.748628: Current learning rate: 0.00235\n",
            "2024-12-25 13:57:58.838149: train_loss -0.9469\n",
            "2024-12-25 13:57:58.845014: val_loss -0.8045\n",
            "2024-12-25 13:57:58.852722: Pseudo dice [0.9348, 0.8402, 0.7808]\n",
            "2024-12-25 13:57:58.858952: Epoch time: 232.1 s\n",
            "2024-12-25 13:57:58.864692: Yayy! New best EMA pseudo Dice: 0.8332\n",
            "2024-12-25 13:58:01.858322: \n",
            "2024-12-25 13:58:01.864592: Epoch 9\n",
            "2024-12-25 13:58:01.874670: Current learning rate: 0.00126\n",
            "2024-12-25 14:01:53.884875: train_loss -0.9476\n",
            "2024-12-25 14:01:53.909745: val_loss -0.8015\n",
            "2024-12-25 14:01:53.919956: Pseudo dice [0.9375, 0.8279, 0.7836]\n",
            "2024-12-25 14:01:53.932044: Epoch time: 232.03 s\n",
            "2024-12-25 14:01:53.940946: Yayy! New best EMA pseudo Dice: 0.8348\n",
            "2024-12-25 14:01:57.984226: Training done.\n",
            "2024-12-25 14:01:58.085777: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 14:01:58.094125: The split file contains 5 splits.\n",
            "2024-12-25 14:01:58.098423: Desired fold for training: 2\n",
            "2024-12-25 14:01:58.102187: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 14:01:58.105898: predicting BraTS2021_00016\n",
            "2024-12-25 14:01:58.130388: BraTS2021_00016, shape torch.Size([4, 138, 172, 135]), rank 0\n",
            "2024-12-25 14:02:12.001093: predicting BraTS2021_00018\n",
            "2024-12-25 14:02:12.027105: BraTS2021_00018, shape torch.Size([4, 138, 177, 136]), rank 0\n",
            "2024-12-25 14:02:14.226910: predicting BraTS2021_00020\n",
            "2024-12-25 14:02:14.249691: BraTS2021_00020, shape torch.Size([4, 137, 182, 137]), rank 0\n",
            "2024-12-25 14:02:24.845258: Validation complete\n",
            "2024-12-25 14:02:24.849323: Mean Validation Dice:  0.8649315743471364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 2d 3 -tr nnUNetTrainer_10epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oy0rX5BIwQn",
        "outputId": "ed765add-d50a-4dfc-b59c-1468e6a4de6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 14:05:38.571541: do_dummy_2d_data_aug: False\n",
            "2024-12-25 14:05:38.576039: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 14:05:38.580431: The split file contains 5 splits.\n",
            "2024-12-25 14:05:38.582657: Desired fold for training: 3\n",
            "2024-12-25 14:05:38.584472: This split has 12 training and 3 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-12-25 14:06:03.792736: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 2d\n",
            " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 80, 'patch_size': [192, 160], 'median_image_size_in_voxels': [174.0, 136.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 174, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3477.0, 'mean': 1033.44775390625, 'median': 913.0, 'min': 75.0, 'percentile_00_5': 212.0, 'percentile_99_5': 2637.0, 'std': 484.8674011230469}, '1': {'max': 10061.0, 'mean': 2287.951416015625, 'median': 2029.0, 'min': 14.0, 'percentile_00_5': 686.0, 'percentile_99_5': 6725.0, 'std': 1055.456298828125}, '2': {'max': 2343.0, 'mean': 790.7552490234375, 'median': 771.0, 'min': 13.0, 'percentile_00_5': 89.0, 'percentile_99_5': 1783.0, 'std': 305.4101867675781}, '3': {'max': 4050.0, 'mean': 1813.7210693359375, 'median': 1795.0, 'min': 44.0, 'percentile_00_5': 471.0, 'percentile_99_5': 3388.0, 'std': 624.7869262695312}}} \n",
            "\n",
            "2024-12-25 14:06:05.134631: unpacking dataset...\n",
            "2024-12-25 14:06:14.013846: unpacking done...\n",
            "2024-12-25 14:06:14.084003: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-12-25 14:06:14.107424: \n",
            "2024-12-25 14:06:14.112780: Epoch 0\n",
            "2024-12-25 14:06:14.118732: Current learning rate: 0.01\n",
            "2024-12-25 14:10:14.504266: train_loss -0.4432\n",
            "2024-12-25 14:10:14.521825: val_loss -0.7136\n",
            "2024-12-25 14:10:14.534844: Pseudo dice [0.822, 0.6812, 0.8354]\n",
            "2024-12-25 14:10:14.543304: Epoch time: 240.4 s\n",
            "2024-12-25 14:10:14.547976: Yayy! New best EMA pseudo Dice: 0.7796\n",
            "2024-12-25 14:10:17.167487: \n",
            "2024-12-25 14:10:17.175784: Epoch 1\n",
            "2024-12-25 14:10:17.184086: Current learning rate: 0.0091\n",
            "2024-12-25 14:14:10.558861: train_loss -0.8645\n",
            "2024-12-25 14:14:10.567720: val_loss -0.8129\n",
            "2024-12-25 14:14:10.577926: Pseudo dice [0.8543, 0.8729, 0.85]\n",
            "2024-12-25 14:14:10.586518: Epoch time: 233.39 s\n",
            "2024-12-25 14:14:10.591766: Yayy! New best EMA pseudo Dice: 0.7875\n",
            "2024-12-25 14:14:13.542043: \n",
            "2024-12-25 14:14:13.549571: Epoch 2\n",
            "2024-12-25 14:14:13.556738: Current learning rate: 0.00818\n",
            "2024-12-25 14:18:05.215585: train_loss -0.9064\n",
            "2024-12-25 14:18:05.223330: val_loss -0.8506\n",
            "2024-12-25 14:18:05.228555: Pseudo dice [0.8739, 0.9122, 0.8732]\n",
            "2024-12-25 14:18:05.233827: Epoch time: 231.68 s\n",
            "2024-12-25 14:18:05.239492: Yayy! New best EMA pseudo Dice: 0.7974\n",
            "2024-12-25 14:18:08.194222: \n",
            "2024-12-25 14:18:08.200448: Epoch 3\n",
            "2024-12-25 14:18:08.206356: Current learning rate: 0.00725\n",
            "2024-12-25 14:22:00.796396: train_loss -0.9217\n",
            "2024-12-25 14:22:00.804193: val_loss -0.8638\n",
            "2024-12-25 14:22:00.809832: Pseudo dice [0.8872, 0.9222, 0.8804]\n",
            "2024-12-25 14:22:00.815826: Epoch time: 232.6 s\n",
            "2024-12-25 14:22:00.822049: Yayy! New best EMA pseudo Dice: 0.8073\n",
            "2024-12-25 14:22:04.156245: \n",
            "2024-12-25 14:22:04.166513: Epoch 4\n",
            "2024-12-25 14:22:04.174767: Current learning rate: 0.00631\n",
            "2024-12-25 14:25:56.109056: train_loss -0.9292\n",
            "2024-12-25 14:25:56.117711: val_loss -0.8505\n",
            "2024-12-25 14:25:56.125832: Pseudo dice [0.8735, 0.9202, 0.8709]\n",
            "2024-12-25 14:25:56.133080: Epoch time: 231.95 s\n",
            "2024-12-25 14:25:56.140969: Yayy! New best EMA pseudo Dice: 0.8154\n",
            "2024-12-25 14:25:59.227470: \n",
            "2024-12-25 14:25:59.233532: Epoch 5\n",
            "2024-12-25 14:25:59.241039: Current learning rate: 0.00536\n",
            "2024-12-25 14:29:52.207662: train_loss -0.9336\n",
            "2024-12-25 14:29:52.229285: val_loss -0.8624\n",
            "2024-12-25 14:29:52.234671: Pseudo dice [0.8871, 0.9215, 0.8754]\n",
            "2024-12-25 14:29:52.242101: Epoch time: 232.98 s\n",
            "2024-12-25 14:29:52.247900: Yayy! New best EMA pseudo Dice: 0.8233\n",
            "2024-12-25 14:29:54.981187: \n",
            "2024-12-25 14:29:54.990305: Epoch 6\n",
            "2024-12-25 14:29:54.997352: Current learning rate: 0.00438\n",
            "2024-12-25 14:33:48.183462: train_loss -0.9371\n",
            "2024-12-25 14:33:48.190071: val_loss -0.8681\n",
            "2024-12-25 14:33:48.197763: Pseudo dice [0.8872, 0.9321, 0.8827]\n",
            "2024-12-25 14:33:48.204067: Epoch time: 233.2 s\n",
            "2024-12-25 14:33:48.212090: Yayy! New best EMA pseudo Dice: 0.8311\n",
            "2024-12-25 14:33:51.122299: \n",
            "2024-12-25 14:33:51.127534: Epoch 7\n",
            "2024-12-25 14:33:51.134872: Current learning rate: 0.00338\n",
            "2024-12-25 14:37:43.741124: train_loss -0.9395\n",
            "2024-12-25 14:37:43.759108: val_loss -0.8726\n",
            "2024-12-25 14:37:43.766834: Pseudo dice [0.8909, 0.9351, 0.8862]\n",
            "2024-12-25 14:37:43.772775: Epoch time: 232.62 s\n",
            "2024-12-25 14:37:43.778768: Yayy! New best EMA pseudo Dice: 0.8384\n",
            "2024-12-25 14:37:46.756750: \n",
            "2024-12-25 14:37:46.778371: Epoch 8\n",
            "2024-12-25 14:37:46.786661: Current learning rate: 0.00235\n",
            "2024-12-25 14:41:39.786853: train_loss -0.9406\n",
            "2024-12-25 14:41:39.795396: val_loss -0.8654\n",
            "2024-12-25 14:41:39.802614: Pseudo dice [0.8826, 0.9282, 0.8841]\n",
            "2024-12-25 14:41:39.808687: Epoch time: 233.03 s\n",
            "2024-12-25 14:41:39.816732: Yayy! New best EMA pseudo Dice: 0.8444\n",
            "2024-12-25 14:41:42.828256: \n",
            "2024-12-25 14:41:42.838477: Epoch 9\n",
            "2024-12-25 14:41:42.851080: Current learning rate: 0.00126\n",
            "2024-12-25 14:45:35.363072: train_loss -0.9418\n",
            "2024-12-25 14:45:35.370598: val_loss -0.8732\n",
            "2024-12-25 14:45:35.376838: Pseudo dice [0.8932, 0.9297, 0.8872]\n",
            "2024-12-25 14:45:35.384831: Epoch time: 232.54 s\n",
            "2024-12-25 14:45:35.388976: Yayy! New best EMA pseudo Dice: 0.8503\n",
            "2024-12-25 14:45:39.185426: Training done.\n",
            "2024-12-25 14:45:39.268615: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 14:45:39.277149: The split file contains 5 splits.\n",
            "2024-12-25 14:45:39.281229: Desired fold for training: 3\n",
            "2024-12-25 14:45:39.285539: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 14:45:39.289837: predicting BraTS2021_00006\n",
            "2024-12-25 14:45:39.315266: BraTS2021_00006, shape torch.Size([4, 136, 177, 134]), rank 0\n",
            "2024-12-25 14:45:52.306812: predicting BraTS2021_00014\n",
            "2024-12-25 14:45:52.330114: BraTS2021_00014, shape torch.Size([4, 126, 178, 136]), rank 0\n",
            "2024-12-25 14:45:54.401557: predicting BraTS2021_00019\n",
            "2024-12-25 14:45:54.420231: BraTS2021_00019, shape torch.Size([4, 143, 177, 142]), rank 0\n",
            "2024-12-25 14:46:05.405556: Validation complete\n",
            "2024-12-25 14:46:05.408047: Mean Validation Dice:  0.7221643220670457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 2d 4 -tr nnUNetTrainer_10epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKpk27E8SVR-",
        "outputId": "41e4dd58-5127-445c-f67e-eee8fa50fcf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 14:47:30.074362: do_dummy_2d_data_aug: False\n",
            "2024-12-25 14:47:30.079059: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 14:47:30.096331: The split file contains 5 splits.\n",
            "2024-12-25 14:47:30.099926: Desired fold for training: 4\n",
            "2024-12-25 14:47:30.102204: This split has 12 training and 3 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-12-25 14:47:55.032644: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 2d\n",
            " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 80, 'patch_size': [192, 160], 'median_image_size_in_voxels': [174.0, 136.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 174, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3477.0, 'mean': 1033.44775390625, 'median': 913.0, 'min': 75.0, 'percentile_00_5': 212.0, 'percentile_99_5': 2637.0, 'std': 484.8674011230469}, '1': {'max': 10061.0, 'mean': 2287.951416015625, 'median': 2029.0, 'min': 14.0, 'percentile_00_5': 686.0, 'percentile_99_5': 6725.0, 'std': 1055.456298828125}, '2': {'max': 2343.0, 'mean': 790.7552490234375, 'median': 771.0, 'min': 13.0, 'percentile_00_5': 89.0, 'percentile_99_5': 1783.0, 'std': 305.4101867675781}, '3': {'max': 4050.0, 'mean': 1813.7210693359375, 'median': 1795.0, 'min': 44.0, 'percentile_00_5': 471.0, 'percentile_99_5': 3388.0, 'std': 624.7869262695312}}} \n",
            "\n",
            "2024-12-25 14:47:56.466712: unpacking dataset...\n",
            "2024-12-25 14:48:05.477118: unpacking done...\n",
            "2024-12-25 14:48:05.540587: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-12-25 14:48:05.560013: \n",
            "2024-12-25 14:48:05.566019: Epoch 0\n",
            "2024-12-25 14:48:05.571380: Current learning rate: 0.01\n",
            "2024-12-25 14:52:06.309497: train_loss -0.3796\n",
            "2024-12-25 14:52:06.318272: val_loss -0.6625\n",
            "2024-12-25 14:52:06.340825: Pseudo dice [0.7653, 0.7633, 0.7528]\n",
            "2024-12-25 14:52:06.347749: Epoch time: 240.75 s\n",
            "2024-12-25 14:52:06.356594: Yayy! New best EMA pseudo Dice: 0.7604\n",
            "2024-12-25 14:52:09.082873: \n",
            "2024-12-25 14:52:09.089713: Epoch 1\n",
            "2024-12-25 14:52:09.096010: Current learning rate: 0.0091\n",
            "2024-12-25 14:56:04.323895: train_loss -0.856\n",
            "2024-12-25 14:56:04.333520: val_loss -0.7128\n",
            "2024-12-25 14:56:04.343136: Pseudo dice [0.7932, 0.8126, 0.7376]\n",
            "2024-12-25 14:56:04.362108: Epoch time: 235.24 s\n",
            "2024-12-25 14:56:04.369010: Yayy! New best EMA pseudo Dice: 0.7625\n",
            "2024-12-25 14:56:07.106087: \n",
            "2024-12-25 14:56:07.114811: Epoch 2\n",
            "2024-12-25 14:56:07.119825: Current learning rate: 0.00818\n",
            "2024-12-25 15:00:00.053070: train_loss -0.9051\n",
            "2024-12-25 15:00:00.061909: val_loss -0.7179\n",
            "2024-12-25 15:00:00.071110: Pseudo dice [0.8023, 0.819, 0.7442]\n",
            "2024-12-25 15:00:00.082801: Epoch time: 232.95 s\n",
            "2024-12-25 15:00:00.087884: Yayy! New best EMA pseudo Dice: 0.7651\n",
            "2024-12-25 15:00:03.084587: \n",
            "2024-12-25 15:00:03.094473: Epoch 3\n",
            "2024-12-25 15:00:03.103695: Current learning rate: 0.00725\n",
            "2024-12-25 15:03:54.996526: train_loss -0.9227\n",
            "2024-12-25 15:03:55.004837: val_loss -0.6917\n",
            "2024-12-25 15:03:55.013192: Pseudo dice [0.7873, 0.7964, 0.7272]\n",
            "2024-12-25 15:03:55.019642: Epoch time: 231.91 s\n",
            "2024-12-25 15:03:55.025901: Yayy! New best EMA pseudo Dice: 0.7656\n",
            "2024-12-25 15:03:58.362173: \n",
            "2024-12-25 15:03:58.367866: Epoch 4\n",
            "2024-12-25 15:03:58.376441: Current learning rate: 0.00631\n",
            "2024-12-25 15:07:52.591153: train_loss -0.9314\n",
            "2024-12-25 15:07:52.597617: val_loss -0.7136\n",
            "2024-12-25 15:07:52.605403: Pseudo dice [0.8049, 0.8012, 0.7421]\n",
            "2024-12-25 15:07:52.610891: Epoch time: 234.23 s\n",
            "2024-12-25 15:07:52.616222: Yayy! New best EMA pseudo Dice: 0.7673\n",
            "2024-12-25 15:07:55.626563: \n",
            "2024-12-25 15:07:55.634149: Epoch 5\n",
            "2024-12-25 15:07:55.642917: Current learning rate: 0.00536\n",
            "2024-12-25 15:11:47.621485: train_loss -0.9357\n",
            "2024-12-25 15:11:47.632014: val_loss -0.724\n",
            "2024-12-25 15:11:47.643382: Pseudo dice [0.8082, 0.8081, 0.7522]\n",
            "2024-12-25 15:11:47.650979: Epoch time: 232.0 s\n",
            "2024-12-25 15:11:47.659150: Yayy! New best EMA pseudo Dice: 0.7696\n",
            "2024-12-25 15:11:50.641857: \n",
            "2024-12-25 15:11:50.649240: Epoch 6\n",
            "2024-12-25 15:11:50.658294: Current learning rate: 0.00438\n",
            "2024-12-25 15:15:43.883518: train_loss -0.9383\n",
            "2024-12-25 15:15:43.894477: val_loss -0.728\n",
            "2024-12-25 15:15:43.905746: Pseudo dice [0.8095, 0.8183, 0.7511]\n",
            "2024-12-25 15:15:43.913940: Epoch time: 233.24 s\n",
            "2024-12-25 15:15:43.923003: Yayy! New best EMA pseudo Dice: 0.7719\n",
            "2024-12-25 15:15:47.083095: \n",
            "2024-12-25 15:15:47.091032: Epoch 7\n",
            "2024-12-25 15:15:47.101165: Current learning rate: 0.00338\n",
            "2024-12-25 15:19:39.863259: train_loss -0.9411\n",
            "2024-12-25 15:19:39.874949: val_loss -0.7393\n",
            "2024-12-25 15:19:39.879120: Pseudo dice [0.8154, 0.829, 0.7606]\n",
            "2024-12-25 15:19:39.884454: Epoch time: 232.78 s\n",
            "2024-12-25 15:19:39.889971: Yayy! New best EMA pseudo Dice: 0.7749\n",
            "2024-12-25 15:19:43.062054: \n",
            "2024-12-25 15:19:43.073434: Epoch 8\n",
            "2024-12-25 15:19:43.082767: Current learning rate: 0.00235\n",
            "2024-12-25 15:23:36.663081: train_loss -0.9425\n",
            "2024-12-25 15:23:36.671410: val_loss -0.7189\n",
            "2024-12-25 15:23:36.679226: Pseudo dice [0.8026, 0.8091, 0.7513]\n",
            "2024-12-25 15:23:36.685360: Epoch time: 233.6 s\n",
            "2024-12-25 15:23:36.692107: Yayy! New best EMA pseudo Dice: 0.7761\n",
            "2024-12-25 15:23:39.834066: \n",
            "2024-12-25 15:23:39.842385: Epoch 9\n",
            "2024-12-25 15:23:39.850790: Current learning rate: 0.00126\n",
            "2024-12-25 15:27:30.572233: train_loss -0.943\n",
            "2024-12-25 15:27:30.580648: val_loss -0.7268\n",
            "2024-12-25 15:27:30.586519: Pseudo dice [0.8125, 0.8, 0.7623]\n",
            "2024-12-25 15:27:30.595803: Epoch time: 230.74 s\n",
            "2024-12-25 15:27:30.602152: Yayy! New best EMA pseudo Dice: 0.7777\n",
            "2024-12-25 15:27:34.793467: Training done.\n",
            "2024-12-25 15:27:34.886328: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 15:27:34.894641: The split file contains 5 splits.\n",
            "2024-12-25 15:27:34.898940: Desired fold for training: 4\n",
            "2024-12-25 15:27:34.904473: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 15:27:34.909886: predicting BraTS2021_00002\n",
            "2024-12-25 15:27:34.935678: BraTS2021_00002, shape torch.Size([4, 135, 174, 133]), rank 0\n",
            "2024-12-25 15:27:48.739289: predicting BraTS2021_00003\n",
            "2024-12-25 15:27:48.759267: BraTS2021_00003, shape torch.Size([4, 140, 178, 141]), rank 0\n",
            "2024-12-25 15:27:51.021207: predicting BraTS2021_00008\n",
            "2024-12-25 15:27:51.057232: BraTS2021_00008, shape torch.Size([4, 133, 168, 142]), rank 0\n",
            "2024-12-25 15:28:01.076798: Validation complete\n",
            "2024-12-25 15:28:01.079755: Mean Validation Dice:  0.766509496410383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 2d  0 -tr nnUNetTrainer_10epochs --val --npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIRL1XcffAXt",
        "outputId": "04b5a4b5-67c3-4074-f77d-7a6bd9fe59d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 15:43:59.066341: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n",
            "2024-12-25 15:44:00.769749: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 15:44:00.778232: The split file contains 5 splits.\n",
            "2024-12-25 15:44:00.782189: Desired fold for training: 0\n",
            "2024-12-25 15:44:00.789778: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 15:44:00.794469: predicting BraTS2021_00000\n",
            "2024-12-25 15:44:00.818696: BraTS2021_00000, shape torch.Size([4, 146, 171, 136]), rank 0\n",
            "2024-12-25 15:44:27.875639: predicting BraTS2021_00011\n",
            "2024-12-25 15:44:27.899582: BraTS2021_00011, shape torch.Size([4, 142, 166, 141]), rank 0\n",
            "2024-12-25 15:44:37.871360: predicting BraTS2021_00017\n",
            "2024-12-25 15:44:37.911520: BraTS2021_00017, shape torch.Size([4, 138, 174, 147]), rank 0\n",
            "2024-12-25 15:44:50.683688: Validation complete\n",
            "2024-12-25 15:44:50.686378: Mean Validation Dice:  0.7981283107083937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train Dataset137_BraTS2021 2d  1 -tr nnUNetTrainer_10epochs --val --npz\n",
        "!nnUNetv2_train Dataset137_BraTS2021 2d  2 -tr nnUNetTrainer_10epochs --val --npz\n",
        "!nnUNetv2_train Dataset137_BraTS2021 2d  3 -tr nnUNetTrainer_10epochs --val --npz\n",
        "!nnUNetv2_train Dataset137_BraTS2021 2d  4 -tr nnUNetTrainer_10epochs --val --npz\n",
        "!nnUNetv2_train Dataset137_BraTS2021 3d_fullres  0 -tr nnUNetTrainer_10epochs --val --npz\n",
        "!nnUNetv2_train Dataset137_BraTS2021 3d_fullres  1 -tr nnUNetTrainer_10epochs --val --npz\n",
        "!nnUNetv2_train Dataset137_BraTS2021 3d_fullres  2 -tr nnUNetTrainer_10epochs --val --npz\n",
        "!nnUNetv2_train Dataset137_BraTS2021 3d_fullres  3 -tr nnUNetTrainer_10epochs --val --npz\n",
        "!nnUNetv2_train Dataset137_BraTS2021 3d_fullres  4 -tr nnUNetTrainer_10epochs --val --npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGjhXt-Mfk6j",
        "outputId": "4aa1f2ae-acb1-49bb-e08a-4a8ec8b3924d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 15:46:55.495456: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n",
            "2024-12-25 15:46:57.217355: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 15:46:57.225294: The split file contains 5 splits.\n",
            "2024-12-25 15:46:57.229839: Desired fold for training: 1\n",
            "2024-12-25 15:46:57.234767: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 15:46:57.237831: predicting BraTS2021_00005\n",
            "2024-12-25 15:46:57.259082: BraTS2021_00005, shape torch.Size([4, 136, 161, 134]), rank 0\n",
            "2024-12-25 15:47:17.134130: predicting BraTS2021_00009\n",
            "2024-12-25 15:47:17.178224: BraTS2021_00009, shape torch.Size([4, 132, 167, 135]), rank 0\n",
            "2024-12-25 15:47:23.146498: predicting BraTS2021_00012\n",
            "2024-12-25 15:47:23.167645: BraTS2021_00012, shape torch.Size([4, 141, 178, 143]), rank 0\n",
            "2024-12-25 15:47:36.156250: Validation complete\n",
            "2024-12-25 15:47:36.159483: Mean Validation Dice:  0.6004122535504662\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 15:47:45.393051: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n",
            "2024-12-25 15:47:47.115544: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 15:47:47.123832: The split file contains 5 splits.\n",
            "2024-12-25 15:47:47.128826: Desired fold for training: 2\n",
            "2024-12-25 15:47:47.153820: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 15:47:47.163723: predicting BraTS2021_00016\n",
            "2024-12-25 15:47:47.186625: BraTS2021_00016, shape torch.Size([4, 138, 172, 135]), rank 0\n",
            "2024-12-25 15:48:07.316797: predicting BraTS2021_00018\n",
            "2024-12-25 15:48:07.339091: BraTS2021_00018, shape torch.Size([4, 138, 177, 136]), rank 0\n",
            "2024-12-25 15:48:09.773521: predicting BraTS2021_00020\n",
            "2024-12-25 15:48:09.794392: BraTS2021_00020, shape torch.Size([4, 137, 182, 137]), rank 0\n",
            "2024-12-25 15:48:26.527090: Validation complete\n",
            "2024-12-25 15:48:26.530174: Mean Validation Dice:  0.8649339647316356\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 15:48:35.680326: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n",
            "2024-12-25 15:48:37.384506: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 15:48:37.393301: The split file contains 5 splits.\n",
            "2024-12-25 15:48:37.398023: Desired fold for training: 3\n",
            "2024-12-25 15:48:37.403229: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 15:48:37.408496: predicting BraTS2021_00006\n",
            "2024-12-25 15:48:37.433989: BraTS2021_00006, shape torch.Size([4, 136, 177, 134]), rank 0\n",
            "2024-12-25 15:48:52.800770: predicting BraTS2021_00014\n",
            "2024-12-25 15:48:52.822805: BraTS2021_00014, shape torch.Size([4, 126, 178, 136]), rank 0\n",
            "2024-12-25 15:48:58.212169: predicting BraTS2021_00019\n",
            "2024-12-25 15:48:58.233201: BraTS2021_00019, shape torch.Size([4, 143, 177, 142]), rank 0\n",
            "2024-12-25 15:49:11.345114: Validation complete\n",
            "2024-12-25 15:49:11.347909: Mean Validation Dice:  0.7220679783202272\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 15:49:20.182152: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n",
            "2024-12-25 15:49:21.892187: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 15:49:21.901525: The split file contains 5 splits.\n",
            "2024-12-25 15:49:21.905013: Desired fold for training: 4\n",
            "2024-12-25 15:49:21.910362: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 15:49:21.916011: predicting BraTS2021_00002\n",
            "2024-12-25 15:49:21.953485: BraTS2021_00002, shape torch.Size([4, 135, 174, 133]), rank 0\n",
            "2024-12-25 15:49:41.623063: predicting BraTS2021_00003\n",
            "2024-12-25 15:49:41.655467: BraTS2021_00003, shape torch.Size([4, 140, 178, 141]), rank 0\n",
            "2024-12-25 15:49:47.668456: predicting BraTS2021_00008\n",
            "2024-12-25 15:49:47.696556: BraTS2021_00008, shape torch.Size([4, 133, 168, 142]), rank 0\n",
            "2024-12-25 15:50:00.667395: Validation complete\n",
            "2024-12-25 15:50:00.669992: Mean Validation Dice:  0.7665145847824877\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 15:50:10.203171: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n",
            "2024-12-25 15:50:12.275160: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 15:50:12.284009: The split file contains 5 splits.\n",
            "2024-12-25 15:50:12.287853: Desired fold for training: 0\n",
            "2024-12-25 15:50:12.291768: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 15:50:12.313398: predicting BraTS2021_00000\n",
            "2024-12-25 15:50:12.353704: BraTS2021_00000, shape torch.Size([4, 146, 171, 136]), rank 0\n",
            "2024-12-25 15:50:39.992905: predicting BraTS2021_00011\n",
            "2024-12-25 15:50:40.024226: BraTS2021_00011, shape torch.Size([4, 142, 166, 141]), rank 0\n",
            "2024-12-25 15:50:48.713481: predicting BraTS2021_00017\n",
            "2024-12-25 15:50:48.745373: BraTS2021_00017, shape torch.Size([4, 138, 174, 147]), rank 0\n",
            "2024-12-25 15:51:00.672271: Validation complete\n",
            "2024-12-25 15:51:00.675107: Mean Validation Dice:  0.6440392576167869\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 15:51:10.080001: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n",
            "2024-12-25 15:51:11.900457: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 15:51:11.908928: The split file contains 5 splits.\n",
            "2024-12-25 15:51:11.913294: Desired fold for training: 1\n",
            "2024-12-25 15:51:11.916831: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 15:51:11.922455: predicting BraTS2021_00005\n",
            "2024-12-25 15:51:11.959391: BraTS2021_00005, shape torch.Size([4, 136, 161, 134]), rank 0\n",
            "2024-12-25 15:51:31.749479: predicting BraTS2021_00009\n",
            "2024-12-25 15:51:31.786478: BraTS2021_00009, shape torch.Size([4, 132, 167, 135]), rank 0\n",
            "2024-12-25 15:51:36.700576: predicting BraTS2021_00012\n",
            "2024-12-25 15:51:36.744423: BraTS2021_00012, shape torch.Size([4, 141, 178, 143]), rank 0\n",
            "2024-12-25 15:51:48.113676: Validation complete\n",
            "2024-12-25 15:51:48.116528: Mean Validation Dice:  0.6772849765695951\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 15:51:57.622650: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n",
            "2024-12-25 15:51:59.451279: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 15:51:59.459723: The split file contains 5 splits.\n",
            "2024-12-25 15:51:59.464128: Desired fold for training: 2\n",
            "2024-12-25 15:51:59.467805: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 15:51:59.471619: predicting BraTS2021_00016\n",
            "2024-12-25 15:51:59.508799: BraTS2021_00016, shape torch.Size([4, 138, 172, 135]), rank 0\n",
            "2024-12-25 15:52:19.949358: predicting BraTS2021_00018\n",
            "2024-12-25 15:52:19.998353: BraTS2021_00018, shape torch.Size([4, 138, 177, 136]), rank 0\n",
            "2024-12-25 15:52:28.548040: predicting BraTS2021_00020\n",
            "2024-12-25 15:52:28.581821: BraTS2021_00020, shape torch.Size([4, 137, 182, 137]), rank 0\n",
            "2024-12-25 15:52:40.322768: Validation complete\n",
            "2024-12-25 15:52:40.325918: Mean Validation Dice:  0.8686393083351689\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 15:52:50.003886: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n",
            "2024-12-25 15:52:51.891297: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 15:52:51.899252: The split file contains 5 splits.\n",
            "2024-12-25 15:52:51.903858: Desired fold for training: 3\n",
            "2024-12-25 15:52:51.907371: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 15:52:51.910926: predicting BraTS2021_00006\n",
            "2024-12-25 15:52:51.962082: BraTS2021_00006, shape torch.Size([4, 136, 177, 134]), rank 0\n",
            "2024-12-25 15:53:11.145363: predicting BraTS2021_00014\n",
            "2024-12-25 15:53:11.175470: BraTS2021_00014, shape torch.Size([4, 126, 178, 136]), rank 0\n",
            "2024-12-25 15:53:15.829579: predicting BraTS2021_00019\n",
            "2024-12-25 15:53:15.862013: BraTS2021_00019, shape torch.Size([4, 143, 177, 142]), rank 0\n",
            "2024-12-25 15:53:27.797129: Validation complete\n",
            "2024-12-25 15:53:27.800058: Mean Validation Dice:  0.6615932528835468\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-12-25 15:53:37.606138: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n",
            "2024-12-25 15:53:39.464697: Using splits from existing split file: /content/drive/MyDrive/DATASET/nnUNet_preprocessed/Dataset137_BraTS2021/splits_final.json\n",
            "2024-12-25 15:53:39.486835: The split file contains 5 splits.\n",
            "2024-12-25 15:53:39.490945: Desired fold for training: 4\n",
            "2024-12-25 15:53:39.494519: This split has 12 training and 3 validation cases.\n",
            "2024-12-25 15:53:39.497998: predicting BraTS2021_00002\n",
            "2024-12-25 15:53:39.530849: BraTS2021_00002, shape torch.Size([4, 135, 174, 133]), rank 0\n",
            "2024-12-25 15:53:59.769083: predicting BraTS2021_00003\n",
            "2024-12-25 15:53:59.799335: BraTS2021_00003, shape torch.Size([4, 140, 178, 141]), rank 0\n",
            "2024-12-25 15:54:04.324198: predicting BraTS2021_00008\n",
            "2024-12-25 15:54:04.360995: BraTS2021_00008, shape torch.Size([4, 133, 168, 142]), rank 0\n",
            "2024-12-25 15:54:16.253796: Validation complete\n",
            "2024-12-25 15:54:16.257120: Mean Validation Dice:  0.7101905560580812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_find_best_configuration Dataset137_BraTS2021 -c 2d  3d_fullres -tr nnUNetTrainer_10epochs -f 0 1 2 3 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP_y4i7HbxMj",
        "outputId": "e95bb550-1b0b-406d-de28-76626a37785f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***All results:***\n",
            "nnUNetTrainer_10epochs__nnUNetPlans__2d: 0.7504114184186421\n",
            "nnUNetTrainer_10epochs__nnUNetPlans__3d_fullres: 0.7123494702926356\n",
            "ensemble___nnUNetTrainer_10epochs__nnUNetPlans__2d___nnUNetTrainer_10epochs__nnUNetPlans__3d_fullres___0_1_2_3_4: 0.14285819684568676\n",
            "\n",
            "*Best*: nnUNetTrainer_10epochs__nnUNetPlans__2d: 0.7504114184186421\n",
            "\n",
            "***Determining postprocessing for best model/ensemble***\n",
            "Removing all but the largest foreground region did not improve results!\n",
            "Removing all but the largest component for (1, 2, 3) did not improve results! Dice before: 0.85329 after: 0.85073\n",
            "Removing all but the largest component for (2, 3) did not improve results! Dice before: 0.71225 after: 0.68894\n",
            "Removing all but the largest component for (3,) did not improve results! Dice before: 0.6857 after: 0.64964\n",
            "\n",
            "***Run inference like this:***\n",
            "\n",
            "nnUNetv2_predict -d Dataset137_BraTS2021 -i INPUT_FOLDER -o OUTPUT_FOLDER -f  0 1 2 3 4 -tr nnUNetTrainer_10epochs -c 2d -p nnUNetPlans\n",
            "\n",
            "***Once inference is completed, run postprocessing like this:***\n",
            "\n",
            "nnUNetv2_apply_postprocessing -i OUTPUT_FOLDER -o OUTPUT_FOLDER_PP -pp_pkl_file /content/drive/MyDrive/DATASET/nnUNet_results/Dataset137_BraTS2021/nnUNetTrainer_10epochs__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/postprocessing.pkl -np 8 -plans_json /content/drive/MyDrive/DATASET/nnUNet_results/Dataset137_BraTS2021/nnUNetTrainer_10epochs__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/plans.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_predict -d Dataset137_BraTS2021 -i /content/drive/MyDrive/DATASET/nnUNet_raw/Dataset137_BraTS2021/imagesTs -o /content/drive/MyDrive/DATASET/BraTS2021_2d_predict -f  0 1 2 3 4 -tr nnUNetTrainer_10epochs -c 2d -p nnUNetPlans --save_probabilities\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcSST3ioG_BR",
        "outputId": "07558c7a-299e-4812-ce8d-738bd0a8804f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),\n",
            "There are 10 cases in the source folder\n",
            "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
            "There are 10 cases that I would like to predict\n",
            "\n",
            "Predicting BraTS2021_00021:\n",
            "perform_everything_on_device: True\n",
            "100% 134/134 [00:05<00:00, 25.59it/s]\n",
            "100% 134/134 [00:03<00:00, 39.77it/s]\n",
            "100% 134/134 [00:03<00:00, 39.04it/s]\n",
            "100% 134/134 [00:03<00:00, 38.50it/s]\n",
            "100% 134/134 [00:03<00:00, 39.69it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00021\n",
            "\n",
            "Predicting BraTS2021_00022:\n",
            "perform_everything_on_device: True\n",
            "100% 132/132 [00:03<00:00, 39.83it/s]\n",
            "100% 132/132 [00:03<00:00, 39.69it/s]\n",
            "100% 132/132 [00:03<00:00, 37.87it/s]\n",
            "100% 132/132 [00:03<00:00, 37.02it/s]\n",
            "100% 132/132 [00:03<00:00, 36.77it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00022\n",
            "\n",
            "Predicting BraTS2021_00024:\n",
            "perform_everything_on_device: True\n",
            "100% 140/140 [00:03<00:00, 38.75it/s]\n",
            "100% 140/140 [00:03<00:00, 39.99it/s]\n",
            "100% 140/140 [00:03<00:00, 40.45it/s]\n",
            "100% 140/140 [00:03<00:00, 39.78it/s]\n",
            "100% 140/140 [00:03<00:00, 38.49it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00024\n",
            "\n",
            "Predicting BraTS2021_00025:\n",
            "perform_everything_on_device: True\n",
            "100% 138/138 [00:03<00:00, 38.74it/s]\n",
            "100% 138/138 [00:03<00:00, 40.08it/s]\n",
            "100% 138/138 [00:03<00:00, 40.54it/s]\n",
            "100% 138/138 [00:03<00:00, 37.38it/s]\n",
            "100% 138/138 [00:03<00:00, 37.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00025\n",
            "\n",
            "Predicting BraTS2021_00026:\n",
            "perform_everything_on_device: True\n",
            "100% 142/142 [00:03<00:00, 37.67it/s]\n",
            "100% 142/142 [00:03<00:00, 40.29it/s]\n",
            "100% 142/142 [00:03<00:00, 39.11it/s]\n",
            "100% 142/142 [00:03<00:00, 39.62it/s]\n",
            "100% 142/142 [00:03<00:00, 39.69it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00026\n",
            "\n",
            "Predicting BraTS2021_00028:\n",
            "perform_everything_on_device: True\n",
            "100% 135/135 [00:03<00:00, 38.50it/s]\n",
            "100% 135/135 [00:03<00:00, 39.21it/s]\n",
            "100% 135/135 [00:03<00:00, 39.20it/s]\n",
            "100% 135/135 [00:03<00:00, 39.85it/s]\n",
            "100% 135/135 [00:03<00:00, 39.68it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00028\n",
            "\n",
            "Predicting BraTS2021_00030:\n",
            "perform_everything_on_device: True\n",
            "100% 140/140 [00:03<00:00, 39.75it/s]\n",
            "100% 140/140 [00:03<00:00, 40.44it/s]\n",
            "100% 140/140 [00:03<00:00, 39.48it/s]\n",
            "100% 140/140 [00:03<00:00, 38.99it/s]\n",
            "100% 140/140 [00:03<00:00, 39.88it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00030\n",
            "\n",
            "Predicting BraTS2021_00031:\n",
            "perform_everything_on_device: True\n",
            "100% 146/146 [00:03<00:00, 39.45it/s]\n",
            "100% 146/146 [00:03<00:00, 39.79it/s]\n",
            "100% 146/146 [00:03<00:00, 39.84it/s]\n",
            "100% 146/146 [00:03<00:00, 40.20it/s]\n",
            "100% 146/146 [00:03<00:00, 40.26it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00031\n",
            "\n",
            "Predicting BraTS2021_00032:\n",
            "perform_everything_on_device: True\n",
            "100% 140/140 [00:03<00:00, 38.94it/s]\n",
            "100% 140/140 [00:03<00:00, 40.26it/s]\n",
            "100% 140/140 [00:03<00:00, 40.47it/s]\n",
            "100% 140/140 [00:03<00:00, 40.52it/s]\n",
            "100% 140/140 [00:03<00:00, 40.97it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00032\n",
            "\n",
            "Predicting BraTS2021_00033:\n",
            "perform_everything_on_device: True\n",
            "100% 135/135 [00:03<00:00, 40.17it/s]\n",
            "100% 135/135 [00:03<00:00, 40.53it/s]\n",
            "100% 135/135 [00:03<00:00, 39.43it/s]\n",
            "100% 135/135 [00:03<00:00, 39.79it/s]\n",
            "100% 135/135 [00:03<00:00, 40.70it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_predict -d Dataset137_BraTS2021 -i /content/drive/MyDrive/DATASET/nnUNet_raw/Dataset137_BraTS2021/imagesTs -o /content/drive/MyDrive/DATASET/BraTS2021_3d_fullres_predict -f  0 1 2 3 4 -tr nnUNetTrainer_10epochs -c 3d_fullres -p nnUNetPlans --save_probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKbF51dBJM1M",
        "outputId": "98673d1f-bf90-4d17-d739-78d7075cd9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),\n",
            "There are 10 cases in the source folder\n",
            "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
            "There are 10 cases that I would like to predict\n",
            "\n",
            "Predicting BraTS2021_00021:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:02<00:00,  2.87it/s]\n",
            "100% 8/8 [00:01<00:00,  5.15it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00021\n",
            "\n",
            "Predicting BraTS2021_00022:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00022\n",
            "\n",
            "Predicting BraTS2021_00024:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00024\n",
            "\n",
            "Predicting BraTS2021_00025:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00025\n",
            "\n",
            "Predicting BraTS2021_00026:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00026\n",
            "\n",
            "Predicting BraTS2021_00028:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00028\n",
            "\n",
            "Predicting BraTS2021_00030:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00030\n",
            "\n",
            "Predicting BraTS2021_00031:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00031\n",
            "\n",
            "Predicting BraTS2021_00032:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00032\n",
            "\n",
            "Predicting BraTS2021_00033:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "100% 8/8 [00:01<00:00,  5.14it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with BraTS2021_00033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_ensemble -i /content/drive/MyDrive/DATASET/BraTS2021_2d_predict /content/drive/MyDrive/DATASET/BraTS2021_3d_fullres_predict -o /content/drive/MyDrive/DATASET/BRATS2021_ensemble"
      ],
      "metadata": {
        "id": "PA-ucsMCKS0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_apply_postprocessing -i /content/drive/MyDrive/DATASET/BRATS2021_ensemble  -o /content/drive/MyDrive/DATASET/BRATS2021_ensemble_pp -pp_pkl_file  /content/drive/MyDrive/DATASET/nnUNet_results/Dataset137_BraTS2021/nnUNetTrainer_10epochs__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/postprocessing.pkl -np 8 -plans_json  /content/drive/MyDrive/DATASET/nnUNet_results/Dataset137_BraTS2021/nnUNetTrainer_10epochs__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/plans.json  -dataset_json /content/drive/MyDrive/DATASET/nnUNet_results/Dataset137_BraTS2021/nnUNetTrainer_10epochs__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/dataset.json\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-KU0DC9qLsww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_evaluate_folder -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80GzeHfBY9tv",
        "outputId": "2abb3cfd-e9ab-4df4-d2bc-308fcb7a8d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: nnUNetv2_evaluate_folder [-h] -djfile DJFILE -pfile PFILE [-o O] [-np NP] [--chill]\n",
            "                                gt_folder pred_folder\n",
            "\n",
            "positional arguments:\n",
            "  gt_folder       folder with gt segmentations\n",
            "  pred_folder     folder with predicted segmentations\n",
            "\n",
            "options:\n",
            "  -h, --help      show this help message and exit\n",
            "  -djfile DJFILE  dataset.json file\n",
            "  -pfile PFILE    plans.json file\n",
            "  -o O            Output file. Optional. Default: pred_folder/summary.json\n",
            "  -np NP          number of processes used. Optional. Default: 8\n",
            "  --chill         dont crash if folder_pred does not have all files that are present in folder_gt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_evaluate_folder -djfile /content/drive/MyDrive/DATASET/nnUNet_raw/Dataset137_BraTS2021/dataset.json  -pfile /content/drive/MyDrive/DATASET/nnUNet_results/Dataset137_BraTS2021/nnUNetTrainer_10epochs__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/plans.json    /content/drive/MyDrive/DATASET/nnUNet_raw/Dataset137_BraTS2021/labelsTs  /content/drive/MyDrive/DATASET/BRATS2021_ensemble_pp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9NuY1_fXOBS",
        "outputId": "f52d02d9-5fa5-417d-9157-ec49448fe11e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "\n",
        "def hausdorff_distance(pred, true):\n",
        "    pred_image = sitk.GetImageFromArray(pred.astype(np.uint8))\n",
        "    true_image = sitk.GetImageFromArray(true.astype(np.uint8))\n",
        "    hd_filter = sitk.HausdorffDistanceImageFilter()\n",
        "    hd_filter.Execute(true_image, pred_image)\n",
        "\n",
        "    return hd_filter.GetHausdorffDistance()\n",
        "\n",
        "gt_folder = '/content/drive/MyDrive/DATASET/nnUNet_raw/Dataset137_BraTS2021/labelsTs'\n",
        "pred_folder = '/content/drive/MyDrive/DATASET/BRATS2021_ensemble_pp'\n",
        "\n",
        "for pred_file in os.listdir(pred_folder):\n",
        "    if pred_file.endswith('.nii.gz'):\n",
        "        gt_file = pred_file\n",
        "        gt_file_path = os.path.join(gt_folder, gt_file)\n",
        "        pred_file_path = os.path.join(pred_folder, pred_file)\n",
        "\n",
        "        true_img = sitk.ReadImage(gt_file_path)\n",
        "        pred_img = sitk.ReadImage(pred_file_path)\n",
        "\n",
        "        true_array = sitk.GetArrayFromImage(true_img)\n",
        "        pred_array = sitk.GetArrayFromImage(pred_img)\n",
        "\n",
        "        distance = hausdorff_distance(pred_array, true_array)\n",
        "        print(f'Hausdorff Distance for {pred_file}: {distance}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzjD1BxseZEn",
        "outputId": "453d4c10-cad5-441d-9320-e6c2a5e55c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hausdorff Distance for BraTS2021_00021.nii.gz: 125.92855117089213\n",
            "Hausdorff Distance for BraTS2021_00022.nii.gz: 139.34848402476433\n",
            "Hausdorff Distance for BraTS2021_00024.nii.gz: 135.65397155999526\n",
            "Hausdorff Distance for BraTS2021_00025.nii.gz: 170.33496411482875\n",
            "Hausdorff Distance for BraTS2021_00026.nii.gz: 136.0036764208968\n",
            "Hausdorff Distance for BraTS2021_00028.nii.gz: 138.3943640470955\n",
            "Hausdorff Distance for BraTS2021_00030.nii.gz: 153.60664048145836\n",
            "Hausdorff Distance for BraTS2021_00031.nii.gz: 122.48265183282079\n",
            "Hausdorff Distance for BraTS2021_00032.nii.gz: 148.95972610071487\n",
            "Hausdorff Distance for BraTS2021_00033.nii.gz: 122.94714311442947\n"
          ]
        }
      ]
    }
  ]
}